<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="author" content="Schwertlilien"/><meta name="keyword"/><meta name="description" content="Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search   present a framework called LLMCS: perform few-shot conversational query rewriting for">
<meta property="og:type" content="article">
<meta property="og:title" content="conversation search paper-1">
<meta property="og:url" content="http://example.com/2023/05/11/conversation-search-paper-1/index.html">
<meta property="og:site_name" content="Schwertlilien">
<meta property="og:description" content="Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search   present a framework called LLMCS: perform few-shot conversational query rewriting for">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.328888.xyz/2023/05/10/iYAW2z.png">
<meta property="og:image" content="https://i.328888.xyz/2023/05/10/iYDlzX.png">
<meta property="og:image" content="https://i.328888.xyz/2023/05/11/iYs5SV.png">
<meta property="article:published_time" content="2023-05-11T07:05:31.000Z">
<meta property="article:modified_time" content="2023-05-11T07:06:45.898Z">
<meta property="article:author" content="Schwertlilien">
<meta property="article:tag" content="conversation search">
<meta property="article:tag" content="natural language processing">
<meta property="article:tag" content="paper note">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.328888.xyz/2023/05/10/iYAW2z.png"><title>conversation search paper-1 - Schwertlilien - -----personal blog-----</title><link rel="shortcut icon" href="/img/site-icon.png">
<link rel="stylesheet" href="/css/style.css" id="dm-light">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.4.2/css/all.min.css">

<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="top-nav" ondblclick="scrollToTop()"><div class="nav-info"><div class="nav-icon"><img id="nav-icon" src="/img/site-icon.png"/></div><div class="nav-title"><a id="nav-title" href="/" title="主页">Schwertlilien</a></div></div><div class="nav-ribbon"><div class="top-menu-expanded"><a class="top-menu-item" href="/archives"><span>归档</span></a><a class="top-menu-item" href="/categories"><span>分类</span></a><a class="top-menu-item" href="/tags"><span>标签</span></a><a class="top-menu-item" href="/about"><span>关于</span></a></div><div class="top-search" onclick="toggleSearchWindow()"><div id="top-search-btn" title="搜索"><i class="icon fa-solid fa-magnifying-glass"></i><span>搜索</span></div></div><div id="top-menu-btn" onclick="openTopMenu()" title="打开菜单"><i class="fa-solid fa-bars fa-lg"></i></div></div></div></header><div id="top-menu-hidden"><div class="menu-hidden-content"><div class="menu-hidden-nav"><a class="menu-hidden-item" href="/archives"><i class="fa-solid fa-box-archive fa-sm"></i><span>归档</span></a><a class="menu-hidden-item" href="/categories"><i class="fa-regular fa-folder-open fa-sm"></i><span>分类</span></a><a class="menu-hidden-item" href="/tags"><i class="fa-solid fa-tags fa-sm"></i><span>标签</span></a><a class="menu-hidden-item" href="/about"><i class="fa-solid fa-paw fa-sm"></i><span>关于</span></a></div></div><div class="menu-hidden-blank" onclick="closeTopMenu()"></div></div>
<div class="blog-info"><div class="blog-pic"><img id="blog-pic" src="/img/site-icon.png"/></div><div class="blog-title"><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i><span>Schwertlilien</span><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i></div><div class="blog-desc">As a recoder: notes and ideas.</div></div><div class="main"><div class="main-content"><article class="post"><div class="post-title"><h1><i class="fa-solid fa-paw"></i>conversation search paper-1</h1></div><div class="post-info"><div class="post-info-first-line"><div class="post-date"><i class="icon fa-regular fa-calendar-plus" title="发布日期"></i><time class="publish-time">2023-05-11</time><i class="icon fa-regular fa-calendar-check" title="更新日期"></i><time class="update-time">2023-05-11</time></div>

<div class="post-tags"><i class="icon fa-solid fa-tags" title="标签"></i><a class="post-tag" href="/tags/conversation-search/">conversation search</a><i class="icon fa-solid fa-tags" title="标签"></i><a class="post-tag" href="/tags/natural-language-processing/">natural language processing</a><i class="icon fa-solid fa-tags" title="标签"></i><a class="post-tag" href="/tags/paper-note/">paper note</a></div></div><div class="post-info-second-line"><div class="post-copyright"><i class="icon fa-brands fa-creative-commons" title="版权声明"></i><span>版权声明: </span><a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-hans" title="CC BY-NC-ND 4.0">署名-非商业性使用-禁止演绎 4.0</a></div>
<div class="post-word-count"><i class="icon fa-solid fa-pen-to-square"></i><span>全文约0.8K字</span></div><div class="pageview-post"><i class="icon fa-regular fa-eye"></i><span id="busuanzi_container_page_pv">阅读次数: <span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner"></i></span></span></div></div></div><div class="post-content"><h4
id="large-language-models-know-your-contextual-search-intent-a-prompting-framework-for-conversational-search">Large
Language Models Know Your Contextual Search Intent: A Prompting
Framework for Conversational Search</h4>
<blockquote>
<ul>
<li>present a framework called LLMCS: perform few-shot conversational
query rewriting for conversational search.</li>
<li>3 methods to generate <code>multiple query rewrites</code> &amp;
<code>hypothetical responses</code>
<ul>
<li>aggregating them into an integrated representation (robustly
represent usr' real contextual search intent)</li>
</ul></li>
<li>Experiment: on CAsT-19, CAsT-20</li>
</ul>
</blockquote>
<p><strong>KYW:
</strong><code>Conversational research</code>,<code>passage retrieval</code>,<code>LMMs</code></p>
<h5 id="intro">Intro</h5>
<p>A common and intuitive thread of existing methods for
<code>CS</code>:==CQR==(conversational query rewriting): employ a
rewriting model to rewrite the current query into a de-contextualized
one, then freely adopt any ad-hoc search model.</p>
<p>==BUT CANNOT handle real conversational search scenarios==</p>
<p><img src="https://i.328888.xyz/2023/05/10/iYAW2z.png" /></p>
<blockquote>
<p>few-shot conversational query rewriting?</p>
<p>aim to <strong>reformulate a concise conversational query</strong> to
<strong>a fully specified, context-independent query</strong> that can
be effectively handled by existing information retrieval systems. This
technique is presented in a paper that proposes a few-shot generative
approach to conversational query rewriting.(small samples)</p>
</blockquote>
<p>3methods of LLMCS framework:</p>
<ul>
<li>rewriting prompt</li>
<li>rewriting-then-response prompt</li>
<li>rewriting-and-response prompt</li>
</ul>
<p><strong>Main Ideas:</strong> use LLM to generate query rewrites &amp;
longer hypothetical system responses.</p>
<p>==BUT HOW TO AGGREGATE THESE RESULTS?==</p>
<p><strong>Advantages:</strong></p>
<ul>
<li>additionally generating hypothetical responses(improve
performance)</li>
<li>filter out incorrect search intent, enhance the reasonable
ones(aggregate)</li>
</ul>
<h5 id="methodology">Methodology</h5>
<ol type="1">
<li>recap of CQR--say it again(no use)</li>
</ol>
<p>first, we focus on the task of conversational passage and retrieval.
<span class="math display">\[
C^t=(q^1,r^1,\ldots,q^{t-1},r^{t-1})
\]</span> <span class="math inline">\(q: question, r: results, C:
context\)</span></p>
<p><img src="https://i.328888.xyz/2023/05/10/iYDlzX.png" /></p>
<ol start="2" type="1">
<li>three methods</li>
</ol>
<ul>
<li>Rewriting Prompt--tips:</li>
</ul>
<p>under the multi-turn information-seeking dialog context,</p>
<p>add a few complete multi-turn <strong>search-oriented
conversations</strong> with corresponding manual rewrites as examples
for demonstration.</p>
<p>For <span class="math inline">\(t\)</span>-th: only provide <span
class="math inline">\(Rewrite: C^t\)</span></p>
<blockquote>
<p>even if it's easy and simple prompting, high efficient.</p>
</blockquote>
<p><img src="https://i.328888.xyz/2023/05/11/iYs5SV.png" /></p>
<ul>
<li>Rewriting-then-response prompt</li>
</ul>
<p>use the rewrite(just generated)-&gt;generate a hypothetical
response(have relevant info to answer this question)</p>
<p><strong>The instruction changed into generating a correct ans under
rewrite.</strong></p>
<ul>
<li>Rewriting-and-respense prompt</li>
</ul>
<p>instead of a two-stage manner, generate them all at once with an
integrated instruction</p>
<blockquote>
<p>==why?== "If A MODEL DOES NOT GENERATE THE MARKER WORD(LIKE
<code>RESPONSE:</code>)CORRECTLY, WE CONSIDER IT A GENERATION FAILURE
AND DROP IT."</p>
<p>which it means, if the generated text don't include the marker word,
even if the text is quite close to the response, we still do not think
this's a response.</p>
<p>ok, it just simplifies our solutions and methods.( I THINK SO )</p>
</blockquote>
<ol start="3" type="1">
<li>introduce the <strong>chain-of-mind</strong></li>
</ol>
<p>make LLM decompose a reasoning task into multiple intermediate
steps(中间步骤)</p>
<p>+chain-of-mind</p>
<blockquote>
<p><code>Rewrite: &#123;rewrite&#125;</code> into</p>
<p><code>Rewrite: &#123;chain-of-thought&#125;. So the question should be rewritten as: &#123;rewrite&#125;</code></p>
</blockquote>
<ol start="4" type="1">
<li>aggregation and retrieval</li>
</ol>
<p>aggregate (multiple rewrites and hypothetical responses) into
<strong>an integrated representation</strong>.</p>
<ul>
<li><span class="math inline">\(N\)</span> query rewrites <span
class="math inline">\(Q=(\hat q_1,\ldots,\hat q^N)\)</span></li>
<li><span class="math inline">\(M\)</span> hypothetical responses <span
class="math inline">\(\R=(\hat r_{i1},\ldots,\hat r_{iM})\)</span> for
each rewrite <span class="math inline">\(\hat q_i\)</span></li>
</ul>
<p>to encode each of them into a high-D search intent vector and
aggregate these intent vectors into a <strong>final intent vector <span
class="math inline">\(v\)</span></strong>.</p>
<p>3 ways:</p>
<ul>
<li><p>Maxprob: directly use the highest probability ones.(==high
efficiency==) <span class="math display">\[
For\ Rewrite: &amp;v=f(\hat q_1)\\
For\ RTR\ and\ RAR:&amp;v=\frac{f(\hat q_1)+f(\hat r_{11})}{2}
\]</span></p></li>
<li><p>Self-Consistency: is proposed for the reasoning tasks
-推理任务(the final ans is from a fixed answer set)But in conversational
search, there is no fixed standard ans.</p>
<ul>
<li><p>maybe <strong>some</strong> of generated rewrites and responses
are correct.</p></li>
<li><p>choose the cluster center of all intent vectors as final
vector.</p></li>
<li><p><span class="math display">\[
\hat q^*=&amp;\frac 1 N \sum^N_{i=1}f(\hat q_i)\\
v=&amp;\arg\max_{f(\hat q_i)}f(\hat q_i)^\top\cdot \hat q^*
\]</span></p></li>
<li><p><span class="math inline">\(\hat q^*\)</span> is the cluster
center vector.</p></li>
<li><p>For RTR: 1. select the intent vector <span
class="math inline">\(f(\hat q_k),f(\hat r_{kz})\)</span>(from response,
based on <span class="math inline">\(\hat q_k\)</span>). 𝑘 and 𝑧 are the
finally selected indexes of the rewrite and the response,
respectively.</p></li>
<li><p><span class="math display">\[
k=\arg\max_i f(\hat q_i)^\top\cdot \hat q^*\\
\hat r^*_k=\frac 1 M \sum^M_{j=1}f(\hat r_{kj})\\
z=\arg\max_j f(\hat r_{kj})^\top\cdot \hat r^*_k\\
v=\frac{f(\hat q_k)+f(\hat r_{kz})}{2}
\]</span></p></li>
<li><p>For RAR: no need to select response!(for one <span
class="math inline">\(q\)</span>, only related one <span
class="math inline">\(r\)</span>)</p></li>
<li><p><span class="math display">\[
v =\frac{f(\hat q_k)+f(\hat r_{𝑘1})}2
\]</span></p></li>
</ul></li>
<li><p>Mean: get avg</p>
<ul>
<li><p><span class="math display">\[
①\ v=\frac 1 N \sum^N_{i=1}f(\hat q_i)\\
②\ v=\frac{\sum^N_{i=1}[f(\hat q_i)+\sum^M_{j=1}f(\hat r_{ij})]}{N(M+1)}
\]</span></p></li>
<li><p>①for rewrite,②for RAR&amp;RTR.</p></li>
</ul></li>
</ul>
</div><div class="post-end"><div class="post-prev"><a href="/2023/11/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Ch1-3/" title="上一篇文章"><i class="fa-solid fa-chevron-left fa-lg"></i></a></div><div class="post-next"><a href="/2023/03/28/2023-3-28/" title="下一篇文章"><i class="fa-solid fa-chevron-right fa-lg"></i></a></div></div></article><div class="comment" id="comment"><script src="https://giscus.app/client.js" data-repo="SchwertLin/SwertLin_Blog_Comment" data-repo-id="R_kgDONXjrCQ" data-category="Announcements" data-category-id="DIC_kwDONXjrCc4Cky9X" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async="async"></script></div><div id="post-toc"><aside class="toc-aside"><div class="toc-title"><span><i class="fa-solid fa-paw"></i>目录</span></div><div class="toc-container" id="toc-body"><ol class="toc-content"><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#large-language-models-know-your-contextual-search-intent-a-prompting-framework-for-conversational-search"><span class="toc-content-number">1.</span> <span class="toc-content-text">Large
Language Models Know Your Contextual Search Intent: A Prompting
Framework for Conversational Search</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-5"><a class="toc-content-link" href="#intro"><span class="toc-content-number">1.1.</span> <span class="toc-content-text">Intro</span></a></li><li class="toc-content-item toc-content-level-5"><a class="toc-content-link" href="#methodology"><span class="toc-content-number">1.2.</span> <span class="toc-content-text">Methodology</span></a></li></ol></li></ol></div></aside><div class="toc-blank" onclick="tocToggle()"></div></div><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for(i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async="async"></script></div></div><div id="tool-bar"><div id="tool-bar-main"><div id="tool-toggle" onclick="toolToggle()" title="设置"><i class="fa-solid fa-gear"></i></div><div id="toc-toggle" onclick="tocToggle()" title="目录"><i class="fa-solid fa-list-ul"></i></div><div id="go-to-comment" onclick="gotoComment()" title="评论"><i class="fa-regular fa-message fa-flip-horizontal"></i></div><div id="back-to-top" onclick="scrollToTop()" title="返回顶部"><i class="fa-solid fa-chevron-up"></i></div></div><div id="tool-bar-more" style="display: none;"><div id="darkmode-switch" onclick="darkmodeSwitch()" title="深色模式"><i class="fa-solid fa-circle-half-stroke"></i></div><div id="font-size-increase" onclick="fontSizeIncrease()" title="放大字体"><i class="fa-solid fa-plus"></i></div><div id="font-size-decrease" onclick="fontSizeDecrease()" title="缩小字体"><i class="fa-solid fa-minus"></i></div></div></div><div id="search-panel"><div class="search-container"><div class="search-head"><div class="search-title"><span><i class="fa-solid fa-paw"></i>搜索</span></div><div class="search-close-btn" onclick="toggleSearchWindow()"><i class="fa-regular fa-circle-xmark"></i></div></div><div class="search-box"><i class="fa-solid fa-magnifying-glass"></i><input id="search-input" type="text" placeholder="请输入需要搜索的内容……" value=""/></div><div class="search-body"><div id="search-count">匹配结果数: </div><div id="search-result"></div><div id="search-result-empty">未搜索到匹配的文章。</div></div></div></div><footer><div class="footer-content"><div class="copyright-info"><i class="fa-regular fa-copyright fa-xs"></i><span>2022 - 2025 </span><a href="/about">Schwertlilien</a><i class="fa-solid fa-cat fa-sm"></i><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo</a><span> &amp; </span><a href="https://github.com/chanwj/hexo-theme-meow" target="_blank" title="v2.1.0">Theme Meow</a></div><div class="pageview-site"><span id="busuanzi_container_site_pv">总访问量 : <span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner"></i></span></span><span id="busuanzi_container_site_uv">总访客数 : <span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner"></i></span></span></div></div></footer>
<script>const GLOBAL_CONFIG = {
  comment: { theme: 'preferred_color_scheme'}
}
</script>
<script src="/js/third-party/darkmode.js"></script>
<script>var options = {
  dark: '/css/darkmode.css',
  startAt: '24:00',
  endAt: '06:00',
  checkSystemScheme: 'false',
  saveOnToggle: 'true'
};
var darkMode = new DarkMode(options);
// change comment theme synchronously 同步修改评论区主题
if (darkMode.getMode() == "dark" && (true || true)) {
  if (document.getElementById('comment')) {
    document.getElementById('comment').getElementsByTagName('script')[0].setAttribute('data-theme', 'noborder_dark');
  }
}
</script><script>if (localStorage.getItem('font-size')) {
  document.querySelector('.post-content').style.fontSize = localStorage.getItem('font-size') + 'px';
}
</script>
<script src="/js/theme/tool-bar.js"></script>


<script src="/js/theme/menu.js"></script>


<script src="/js/third-party/clipboard.min.js"></script>


<script src="/js/theme/copy.js"></script>
<script>copyCode();
</script>
<script src="/js/jquery-3.7.1.min.js"></script>


<script src="/js/theme/search.js"></script>
<script>searchFunc('/search.xml', 'search-input', 'search-result');
</script></body></html>