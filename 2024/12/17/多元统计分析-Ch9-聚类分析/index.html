<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="author" content="Schwertlilien"/><meta name="keyword"/><meta name="description" content="Ch9 聚类分析 [TOC] 聚类分析的基本思想: 将样本(or 变量) 按相似程度的大小聚在一起，逐一分类。 相似程度的度量：距离或相似系数代表样本或变量之间的相似程度。  样本之间定义距离 变量之间定义相似系数  9.1 个体聚类&amp;变量聚类 假设有 \(n\) 个个体，每个个体有 \(p\) 个观测变量(指标)。ps:所以对齐不同的细粒度。">
<meta property="og:type" content="article">
<meta property="og:title" content="多元统计分析-Ch9-聚类分析">
<meta property="og:url" content="http://example.com/2024/12/17/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90-Ch9-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/index.html">
<meta property="og:site_name" content="Schwertlilien">
<meta property="og:description" content="Ch9 聚类分析 [TOC] 聚类分析的基本思想: 将样本(or 变量) 按相似程度的大小聚在一起，逐一分类。 相似程度的度量：距离或相似系数代表样本或变量之间的相似程度。  样本之间定义距离 变量之间定义相似系数  9.1 个体聚类&amp;变量聚类 假设有 \(n\) 个个体，每个个体有 \(p\) 个观测变量(指标)。ps:所以对齐不同的细粒度。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-12-17T07:23:17.000Z">
<meta property="article:modified_time" content="2024-12-17T07:27:36.126Z">
<meta property="article:author" content="Schwertlilien">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="多元统计分析">
<meta name="twitter:card" content="summary"><title>多元统计分析-Ch9-聚类分析 - Schwertlilien - -----personal blog-----</title><link rel="shortcut icon" href="/img/site-icon.png">
<link rel="stylesheet" href="/css/style.css" id="dm-light">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.4.2/css/all.min.css">

<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="top-nav" ondblclick="scrollToTop()"><div class="nav-info"><div class="nav-icon"><img id="nav-icon" src="/img/site-icon.png"/></div><div class="nav-title"><a id="nav-title" href="/" title="主页">Schwertlilien</a></div></div><div class="nav-ribbon"><div class="top-menu-expanded"><a class="top-menu-item" href="/archives"><span>归档</span></a><a class="top-menu-item" href="/categories"><span>分类</span></a><a class="top-menu-item" href="/tags"><span>标签</span></a><a class="top-menu-item" href="/about"><span>关于</span></a></div><div class="top-search" onclick="toggleSearchWindow()"><div id="top-search-btn" title="搜索"><i class="icon fa-solid fa-magnifying-glass"></i><span>搜索</span></div></div><div id="top-menu-btn" onclick="openTopMenu()" title="打开菜单"><i class="fa-solid fa-bars fa-lg"></i></div></div></div></header><div id="top-menu-hidden"><div class="menu-hidden-content"><div class="menu-hidden-nav"><a class="menu-hidden-item" href="/archives"><i class="fa-solid fa-box-archive fa-sm"></i><span>归档</span></a><a class="menu-hidden-item" href="/categories"><i class="fa-regular fa-folder-open fa-sm"></i><span>分类</span></a><a class="menu-hidden-item" href="/tags"><i class="fa-solid fa-tags fa-sm"></i><span>标签</span></a><a class="menu-hidden-item" href="/about"><i class="fa-solid fa-paw fa-sm"></i><span>关于</span></a></div></div><div class="menu-hidden-blank" onclick="closeTopMenu()"></div></div>
<div class="blog-info"><div class="blog-pic"><img id="blog-pic" src="/img/site-icon.png"/></div><div class="blog-title"><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i><span>Schwertlilien</span><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i></div><div class="blog-desc">As a recoder: notes and ideas.</div></div><div class="main"><div class="main-content"><article class="post"><div class="post-title"><h1><i class="fa-solid fa-paw"></i>多元统计分析-Ch9-聚类分析</h1></div><div class="post-info"><div class="post-info-first-line"><div class="post-date"><i class="icon fa-regular fa-calendar-plus" title="发布日期"></i><time class="publish-time">2024-12-17</time><i class="icon fa-regular fa-calendar-check" title="更新日期"></i><time class="update-time">2024-12-17</time></div>

<div class="post-tags"><i class="icon fa-solid fa-tags" title="标签"></i><a class="post-tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><i class="icon fa-solid fa-tags" title="标签"></i><a class="post-tag" href="/tags/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/">多元统计分析</a></div></div><div class="post-info-second-line"><div class="post-copyright"><i class="icon fa-brands fa-creative-commons" title="版权声明"></i><span>版权声明: </span><a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-hans" title="CC BY-NC-ND 4.0">署名-非商业性使用-禁止演绎 4.0</a></div>
<div class="post-word-count"><i class="icon fa-solid fa-pen-to-square"></i><span>全文约2.4K字</span></div><div class="pageview-post"><i class="icon fa-regular fa-eye"></i><span id="busuanzi_container_page_pv">阅读次数: <span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner"></i></span></span></div></div></div><div class="post-content"><h1 id="ch9-聚类分析">Ch9 聚类分析</h1>
<p>[TOC]</p>
<p><strong>聚类分析的基本思想: 将样本(or 变量)
按相似程度的大小聚在一起，逐一分类。</strong></p>
<p><strong>相似程度的度量：</strong>距离或相似系数代表样本或变量之间的相似程度。</p>
<ul>
<li>样本之间定义距离</li>
<li>变量之间定义相似系数</li>
</ul>
<h2 id="个体聚类变量聚类">9.1 个体聚类&amp;变量聚类</h2>
<p>假设有 <span class="math inline">\(n\)</span> 个个体，每个个体有
<span class="math inline">\(p\)</span>
个观测变量(指标)。<em>ps:所以对齐不同的细粒度。</em></p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>个体聚类</th>
<th>变量聚类</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>根据<strong>个体与个体间观测值</strong>的差别和相似之处，将这 <span
class="math inline">\(n\)</span> 个个体分成若干个类别。</td>
<td>根据<strong>变量与变量之间</strong>的差别和相似之处，将这 <span
class="math inline">\(p\)</span> 个变量分成若干个类别。</td>
</tr>
<tr class="even">
<td>栗子：欧洲各国语言的语系分类。</td>
<td>栗子：人体部位尺寸的分类。</td>
</tr>
</tbody>
</table>
<h2 id="距离相似系数和匹配系数">9.2 距离、相似系数和匹配系数</h2>
<h3 id="个体聚类">9.2.1 个体聚类</h3>
<p>个体之间的接近程度通常用Minkowski距离来度量。 设 <span
class="math inline">\(x=(x_1,\cdots,x_p)&#39;\)</span>，<span
class="math inline">\(y=(y_1,\cdots,y_p)&#39;\)</span>，则 <span
class="math inline">\(x\)</span> 与 <span
class="math inline">\(y\)</span> 的Minkowski距离为 $ d(x,y)=(_{i =
1}^{p}x_i - y_i<sup>m)</sup>{1/m},其中m&gt;0. $ <span
class="math display">\[
d(x,y)=\begin{cases} \sum_{i = 1}^{p}\vert x_i - y_i\vert, &amp; m = 1\\
\left(\sum_{i = 1}^{p}(x_i - y_i)^2\right)^{1/2}, &amp; m = 2\\
\max_{1\leq i\leq p}\vert x_i - y_i\vert, &amp; m=\infty \end{cases}
\]</span> 分别为绝对距离、欧氏距离、Chebyshev距离。
<strong>注1.</strong> 具体问题可用合适的距离，特别是离散型数据。</p>
<h3 id="变量聚类">9.2.2 变量聚类</h3>
<h4 id="pearson矩相关系数">Pearson矩相关系数</h4>
<p># 变量之间的接近程度通常用Pearson矩相关系数来度量 设变量 <span
class="math inline">\(w\)</span> 和 <span
class="math inline">\(u\)</span> 在 <span
class="math inline">\(n\)</span> 个个体的观测值分别为 <span
class="math inline">\((w_1, \cdots, w_n)\)</span> 和 <span
class="math inline">\((u_1, \cdots, u_n)\)</span>，则变量 <span
class="math inline">\(w\)</span> 和 <span
class="math inline">\(u\)</span> 之间的距离（相似系数）为 <span
class="math display">\[
d(w, u) = r_{w, u} = \frac{\sum_{i = 1}^{n} (w_i - \bar{w})(u_i -
\bar{u})}{\sqrt{\sum_{i = 1}^{n} (w_i - \bar{w})^2} \sqrt{\sum_{i =
1}^{n} (u_i - \bar{u})^2}}
\]</span> 其中，<span class="math inline">\(\bar{w} = n^{-1} \sum_{i =
1}^{n} w_i\)</span>，<span class="math inline">\(\bar{u} = n^{-1}
\sum_{i = 1}^{n} u_i\)</span>。 <strong>注2.</strong> <span
class="math inline">\(r_{w, u} = 1\)</span> 时，<span
class="math inline">\(w \neq u\)</span>。</p>
<h4 id="夹角余弦costheta">夹角余弦<span
class="math inline">\(\cos\theta\)</span></h4>
<p>变量之间的接近程度的另一个常用度量是夹角余弦，定义如下：
设两个变量分别为<span
class="math inline">\(x=(x_1,\cdots,x_n)&#39;\)</span>和<span
class="math inline">\(y=(y_1,\cdots,y_n)&#39;\)</span>，则变量<span
class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>之间的夹角余弦为 <span
class="math display">\[
d(x,y)=\frac{\sum_{i = 1}^{n}x_iy_i}{\sqrt{\sum_{i =
1}^{n}x_i^2}\sqrt{\sum_{i = 1}^{n}y_i^2}}
\]</span> 此度量常用于处理图形的相似性。</p>
<h3 id="匹配系数">9.2.3 匹配系数</h3>
<p>假设有两个观测向量<span
class="math inline">\(x=(x_1,\cdots,x_k)&#39;,y=(y_1,\cdots,y_k)&#39;\)</span>，则<span
class="math inline">\(x\)</span>与<span
class="math inline">\(y\)</span>的匹配系数为: <span
class="math display">\[
d(x,y)=\frac{\sum_{i = 1}^{k}I(x_i = y_i)}{k}
\]</span> 匹配系数常用于属性数据的相似性度量。</p>
<h2 id="聚类方法">9.3 聚类方法</h2>
<p>聚类方法大致分为：<strong>谱系聚类、迭代分块聚类</strong></p>
<p>谱系聚类（比较基本传统）分为以下两种类型（<strong>关键:
类与类之间的度量</strong>）：</p>
<table>
<colgroup>
<col style="width: 9%" />
<col style="width: 45%" />
<col style="width: 45%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>凝聚</th>
<th>分解</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>简介</td>
<td><strong>类别由多到少.</strong></td>
<td><strong>类别由少到多.</strong></td>
</tr>
<tr class="even">
<td>方法</td>
<td>一开始把每个个体(变量)自成一类,然后将最接近的个体(最相似的变量)凝聚为一小类，再将最接近相似)的类凝聚在一起,依次类推直到所有个体(变量)凝聚为一个大类时止.</td>
<td>一开始把所有个体(变量)看成一大类,然后将它分解成两个子类,使这两个子类最为疏远,再将子类分为两个最为疏远的子类,依此类推直到每个个体(变量)都自成一类时止.</td>
</tr>
<tr class="odd">
<td>缺陷</td>
<td>一旦两个个体(变量)被分入同一个类中,则它们以后不再会分入两个不同的类中.</td>
<td>一旦两个个体(变量)被分入两个不同的类中,则它们以后不再会并入同一个类中.</td>
</tr>
<tr class="even">
<td>缺陷（相同）</td>
<td>个体被错误分类无法纠正</td>
<td>个体被错误分类无法纠正</td>
</tr>
<tr class="odd">
<td>缺陷（相同）</td>
<td>计算量大</td>
<td>计算量大</td>
</tr>
</tbody>
</table>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/SchwertLin/Pic/img/image-20241210105249266.png"
alt="image-20241210105249266" />
<figcaption aria-hidden="true">image-20241210105249266</figcaption>
</figure>
<h3 id="类之间距离">9.3.2 类之间距离</h3>
<p>设有两个由个体或变量组成的类 $ _1 = {x_i : i G_1}, _2 = {x_j : j G_2}
$ 类<span class="math inline">\(\pi_1\)</span>与<span
class="math inline">\(\pi_2\)</span>之间的距离<span
class="math inline">\(d(\pi_1, \pi_2)\)</span>常用以下定义方法：</p>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 77%" />
</colgroup>
<thead>
<tr class="header">
<th>方法</th>
<th>公式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(1). 最小距离法</td>
<td>$ d(_1, <em>2) = </em>{ {i G_1, j G_2} } d(x_i, x_j) $</td>
</tr>
<tr class="even">
<td>(2). 最大距离法</td>
<td><span class="math inline">\(d(\pi_1, \pi_2) = \max_{ \{i \in G_1, j
\in G_2\}\  } d(x_i, x_j)\)</span></td>
</tr>
<tr class="odd">
<td>(3). 类平均法</td>
<td><span class="math inline">\(d(\pi_1, \pi_2) = \frac{\sum_{i \in G_1}
\sum_{j \in G_2} d(x_i, x_j)}{n_1 n_2}\)</span>, 其中，<span
class="math inline">\(n_1 = \# \{x_i : i \in G_1\}\)</span>，<span
class="math inline">\(n_2 = \# \{x_j : j \in G_2\}\)</span>。</td>
</tr>
<tr class="even">
<td>(4). 重心法</td>
<td><span class="math inline">\(d(\pi_1, \pi_2) = d(\bar{x}_1,
\bar{x}_2)\)</span>， 其中，<span
class="math inline">\(\bar{x}_1=\frac{\sum_{i\in
G_1}x_i}{n_1}\)</span>，<span
class="math inline">\(\bar{x}_2=\frac{\sum_{j\in
G_2}x_j}{n_2}\)</span>.</td>
</tr>
<tr class="odd">
<td>(5). 离差平方和法</td>
<td><span class="math inline">\(d(\pi_1, \pi_2)=\frac{n_1n_2}{n_1 +
n_2}(\bar{x}_1-\bar{x}_2)&#39;(\bar{x}_1-\bar{x}_2)\)</span></td>
</tr>
</tbody>
</table>
<blockquote>
<p>注3：离差平方和即组间平方和，事实上有 : <span class="math display">\[
\begin{align}
d(\pi_1, \pi_2)&amp;=\frac{n_1n_2}{n_1 +
n_2}(\bar{x}_1-\bar{x}_2)&#39;(\bar{x}_1-\bar{x}_2) \\
&amp;=n_1(\bar{x}_1-\bar{x})&#39;(\bar{x}_1-\bar{x})+n_2(\bar{x}_2-\bar{x})&#39;(\bar{x}_2-\bar{x})\\
其中\bar{x}&amp;=\frac{1}{n_1 + n_2}\left(\sum_{i\in G_1}x_i+\sum_{j\in
G_2}x_j\right)
\end{align}
\]</span></p>
</blockquote>
<p>如果只有两类的话，分解法不靠谱。存在的问题就是：错误是积累的，连锁反应。</p>
<h3 id="对谱系分解的改进迭代分块聚类">9.3.3
对谱系分解的改进：迭代分块聚类</h3>
<p>迭代分块聚类法是一种动态聚类法,其搜索迭代步骤大致如下:</p>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="header">
<th>---</th>
<th>迭代分块聚类法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. 初始分类</td>
<td>将n个个体(变量)初始分为k类,其中,<strong>类的个数k可以事先给定(K-means),也可以在聚类过程中逐步确定(动态K-means)。</strong></td>
</tr>
<tr class="even">
<td>2. 修改分类</td>
<td>对每个个体(变量)逐一进行搜索,若将某个个体变量)分入另一个类后对分类有所改进,则将其移入改进最多的那个类,否则其不移动，仍在原来的类中。</td>
</tr>
<tr class="odd">
<td>3. 重复迭代</td>
<td>在对每个个体(变量)逐一都进行搜索之后,重复第(2)步，直到任何一个个体(变量)都不需要移动为止，从而得到最终分类。</td>
</tr>
</tbody>
</table>
<h4 id="k-means">K-means</h4>
<p><strong>由于初始分类数k事先给定,且迭代过程中不断计算类的重心，故称该聚类方法为k均值法(k-means)</strong>：</p>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="header">
<th>---</th>
<th>K-means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. 初始分类</td>
<td>将几个个体初始分成k类,k事先给定.</td>
</tr>
<tr class="even">
<td>2. 修改分类</td>
<td>计算初始k类的重心。然后对每个个体逐一计算它到初始k类的距离(通常用该个体到类的重心的欧氏距离)。若该个体到其原来的类的距离最近,则它保持类不变，否则它移入离其距离最近的类，重新计算由此变动的两个类的重心。</td>
</tr>
<tr class="odd">
<td>3. 重复迭代</td>
<td>在对所有个体都逐一进行验证,是否需要修改分类之后，重复步骤2),直到没有个体需要移动为止,从而得到最终分类.</td>
</tr>
</tbody>
</table>
<h4 id="动态k-means">动态K-means</h4>
<p>事先给定3个数: 类别数k,阀值 <span
class="math inline">\(c_1\)</span>和 <span
class="math inline">\(c_2\)</span>, <span
class="math inline">\(c_2&gt;c_1&gt; 0\)</span>.</p>
<blockquote>
<p>相较于K-means, 动态K-means在聚类过程中动态地调整聚类中心的数量
K。通常根据数据的分布和内部结构来自动确定合适的 K 值，避免了手动选择 K
值带来的不确定性。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="header">
<th>---</th>
<th>动态K-means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. 选取聚点</td>
<td>取前k个个体作为初始聚点,计算这k个聚点两两之间的距离若最小的距离比<span
class="math inline">\(c_1\)</span>小,则将最小距离的这两个聚点合并在一起,并用它们的重心作为新的聚点，重复上述过程,直到所有的聚点两两之间的距离都不比<span
class="math inline">\(c_1\)</span>小时为止,<strong>因此，此时聚点的个数可能小于k.</strong></td>
</tr>
<tr class="even">
<td>2. 初始分类</td>
<td>对余下的n-k个个体逐一进行计算，对输入的一个个体，分别计算它到所有聚点的距离。若该个体到所有聚点的距离都大于<span
class="math inline">\(c_2\)</span>，则它作为一个新的聚点，这时所有聚点两两之间的距离都不比<span
class="math inline">\(c_1\)</span>小，否则将它归入离它最近的那一类，并重新计算接受该个体的那个类的重心以代替该类原来的聚点。然后重复步骤1)，再次验证所有聚点两两之间的距离是否都不比<span
class="math inline">\(c_1\)</span>小，如果比<span
class="math inline">\(c_1\)</span>小就将其合并，直到所有聚点两两之间的距离都不比<span
class="math inline">\(c_1\)</span>小时止，<strong>该步完成后，聚点的个数可能小于k，也可能大于k</strong>。</td>
</tr>
<tr class="odd">
<td>3. 重复迭代</td>
<td>在对所有个体都逐一进行验证，是否需要修改分类之后，重复步骤2)，直到没有个体需要移动为止，从而得到最终分类。<strong>这时，最终个体的类别数不一定是
k。</strong></td>
</tr>
</tbody>
</table>
<h3 id="例子">例子</h3>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/SchwertLin/Pic/img/image-20241212105328703.png"
alt="image-20241212105328703" />
<figcaption aria-hidden="true">image-20241212105328703</figcaption>
</figure>
<p>计算直径<span class="math inline">\(\{D(i,j)\}\)</span>:</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/SchwertLin/Pic/img/image-20241212105440151.png"
alt="image-20241212105440151" />
<figcaption aria-hidden="true">image-20241212105440151</figcaption>
</figure>
<p>计算最小目标函数：</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/SchwertLin/Pic/img/image-20241212105718921.png"
alt="image-20241212105718921" />
<figcaption aria-hidden="true">image-20241212105718921</figcaption>
</figure>
<p>最终的3类划分：<span
class="math inline">\(G_1=\{x_1\},G_2=\{x_2,x_3,x_4,x_5,x_6,x_7\},G_3=\{x_8,x_9,x_{10},x_{11}\}\)</span></p>
<p>确定k：从<span
class="math inline">\((k,obj[P^*(n,k)])\)</span>图上的曲线变化率，分成3类或4类最为合适。</p>
<figure>
<img
src="https://cdn.jsdelivr.net/gh/SchwertLin/Pic/img/image-20241212110656970.png"
alt="image-20241212110656970" />
<figcaption aria-hidden="true">image-20241212110656970</figcaption>
</figure>
</div><div class="post-end"><div class="post-prev"><a href="/2024/12/17/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90-%E5%A4%8D%E4%B9%A0-%E4%B8%8A/" title="上一篇文章"><i class="fa-solid fa-chevron-left fa-lg"></i></a></div><div class="post-next"><a href="/2024/12/17/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90-Ch8-%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/" title="下一篇文章"><i class="fa-solid fa-chevron-right fa-lg"></i></a></div></div></article><div class="comment" id="comment"><script src="https://giscus.app/client.js" data-repo="SchwertLin/SwertLin_Blog_Comment" data-repo-id="R_kgDONXjrCQ" data-category="Announcements" data-category-id="DIC_kwDONXjrCc4Cky9X" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async="async"></script></div><div id="post-toc"><aside class="toc-aside"><div class="toc-title"><span><i class="fa-solid fa-paw"></i>目录</span></div><div class="toc-container" id="toc-body"><ol class="toc-content"><li class="toc-content-item toc-content-level-1"><a class="toc-content-link" href="#ch9-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90"><span class="toc-content-number">1.</span> <span class="toc-content-text">Ch9 聚类分析</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E4%B8%AA%E4%BD%93%E8%81%9A%E7%B1%BB%E5%8F%98%E9%87%8F%E8%81%9A%E7%B1%BB"><span class="toc-content-number">1.1.</span> <span class="toc-content-text">9.1 个体聚类&amp;变量聚类</span></a></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E8%B7%9D%E7%A6%BB%E7%9B%B8%E4%BC%BC%E7%B3%BB%E6%95%B0%E5%92%8C%E5%8C%B9%E9%85%8D%E7%B3%BB%E6%95%B0"><span class="toc-content-number">1.2.</span> <span class="toc-content-text">9.2 距离、相似系数和匹配系数</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E4%B8%AA%E4%BD%93%E8%81%9A%E7%B1%BB"><span class="toc-content-number">1.2.1.</span> <span class="toc-content-text">9.2.1 个体聚类</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%8F%98%E9%87%8F%E8%81%9A%E7%B1%BB"><span class="toc-content-number">1.2.2.</span> <span class="toc-content-text">9.2.2 变量聚类</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#pearson%E7%9F%A9%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-content-number">1.2.2.1.</span> <span class="toc-content-text">Pearson矩相关系数</span></a></li><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#%E5%A4%B9%E8%A7%92%E4%BD%99%E5%BC%A6costheta"><span class="toc-content-number">1.2.2.2.</span> <span class="toc-content-text">夹角余弦\(\cos\theta\)</span></a></li></ol></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%8C%B9%E9%85%8D%E7%B3%BB%E6%95%B0"><span class="toc-content-number">1.2.3.</span> <span class="toc-content-text">9.2.3 匹配系数</span></a></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95"><span class="toc-content-number">1.3.</span> <span class="toc-content-text">9.3 聚类方法</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E7%B1%BB%E4%B9%8B%E9%97%B4%E8%B7%9D%E7%A6%BB"><span class="toc-content-number">1.3.1.</span> <span class="toc-content-text">9.3.2 类之间距离</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%AF%B9%E8%B0%B1%E7%B3%BB%E5%88%86%E8%A7%A3%E7%9A%84%E6%94%B9%E8%BF%9B%E8%BF%AD%E4%BB%A3%E5%88%86%E5%9D%97%E8%81%9A%E7%B1%BB"><span class="toc-content-number">1.3.2.</span> <span class="toc-content-text">9.3.3
对谱系分解的改进：迭代分块聚类</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#k-means"><span class="toc-content-number">1.3.2.1.</span> <span class="toc-content-text">K-means</span></a></li><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#%E5%8A%A8%E6%80%81k-means"><span class="toc-content-number">1.3.2.2.</span> <span class="toc-content-text">动态K-means</span></a></li></ol></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E4%BE%8B%E5%AD%90"><span class="toc-content-number">1.3.3.</span> <span class="toc-content-text">例子</span></a></li></ol></li></ol></li></ol></div></aside><div class="toc-blank" onclick="tocToggle()"></div></div><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for(i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async="async"></script></div></div><div id="tool-bar"><div id="tool-bar-main"><div id="tool-toggle" onclick="toolToggle()" title="设置"><i class="fa-solid fa-gear"></i></div><div id="toc-toggle" onclick="tocToggle()" title="目录"><i class="fa-solid fa-list-ul"></i></div><div id="go-to-comment" onclick="gotoComment()" title="评论"><i class="fa-regular fa-message fa-flip-horizontal"></i></div><div id="back-to-top" onclick="scrollToTop()" title="返回顶部"><i class="fa-solid fa-chevron-up"></i></div></div><div id="tool-bar-more" style="display: none;"><div id="darkmode-switch" onclick="darkmodeSwitch()" title="深色模式"><i class="fa-solid fa-circle-half-stroke"></i></div><div id="font-size-increase" onclick="fontSizeIncrease()" title="放大字体"><i class="fa-solid fa-plus"></i></div><div id="font-size-decrease" onclick="fontSizeDecrease()" title="缩小字体"><i class="fa-solid fa-minus"></i></div></div></div><div id="search-panel"><div class="search-container"><div class="search-head"><div class="search-title"><span><i class="fa-solid fa-paw"></i>搜索</span></div><div class="search-close-btn" onclick="toggleSearchWindow()"><i class="fa-regular fa-circle-xmark"></i></div></div><div class="search-box"><i class="fa-solid fa-magnifying-glass"></i><input id="search-input" type="text" placeholder="请输入需要搜索的内容……" value=""/></div><div class="search-body"><div id="search-count">匹配结果数: </div><div id="search-result"></div><div id="search-result-empty">未搜索到匹配的文章。</div></div></div></div><footer><div class="footer-content"><div class="copyright-info"><i class="fa-regular fa-copyright fa-xs"></i><span>2022 - 2025 </span><a href="/about">Schwertlilien</a><i class="fa-solid fa-cat fa-sm"></i><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo</a><span> &amp; </span><a href="https://github.com/chanwj/hexo-theme-meow" target="_blank" title="v2.1.0">Theme Meow</a></div><div class="pageview-site"><span id="busuanzi_container_site_pv">总访问量 : <span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner"></i></span></span><span id="busuanzi_container_site_uv">总访客数 : <span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner"></i></span></span></div></div></footer>
<script>const GLOBAL_CONFIG = {
  comment: { theme: 'preferred_color_scheme'}
}
</script>
<script src="/js/third-party/darkmode.js"></script>
<script>var options = {
  dark: '/css/darkmode.css',
  startAt: '24:00',
  endAt: '06:00',
  checkSystemScheme: 'false',
  saveOnToggle: 'true'
};
var darkMode = new DarkMode(options);
// change comment theme synchronously 同步修改评论区主题
if (darkMode.getMode() == "dark" && (true || true)) {
  if (document.getElementById('comment')) {
    document.getElementById('comment').getElementsByTagName('script')[0].setAttribute('data-theme', 'noborder_dark');
  }
}
</script><script>if (localStorage.getItem('font-size')) {
  document.querySelector('.post-content').style.fontSize = localStorage.getItem('font-size') + 'px';
}
</script>
<script src="/js/theme/tool-bar.js"></script>


<script src="/js/theme/menu.js"></script>


<script src="/js/third-party/clipboard.min.js"></script>


<script src="/js/theme/copy.js"></script>
<script>copyCode();
</script>
<script src="/js/jquery-3.7.1.min.js"></script>


<script src="/js/theme/search.js"></script>
<script>searchFunc('/search.xml', 'search-input', 'search-result');
</script></body></html>