<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="author" content="Schwertlilien"/><meta name="keyword"/><meta name="description" content="期末复习2  各分析考试占比较少。  [TOC] Ch5 相关分析  不考的：  样本复相关系数分布（独立性检验，不考） 典型相关分析所有k步、作用 样本典型相关分析 典型相关变量个数检验 广义相关系数   5.1 复相关系数 5.1.1 总体复相关系数  知道基本定义即可。证明说是很简单，那么有可能考。  变量\(y_1\)与向量\(Y_2\)之间的复相">
<meta property="og:type" content="article">
<meta property="og:title" content="多元统计分析-复习(下)">
<meta property="og:url" content="http://example.com/2024/12/18/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90-%E5%A4%8D%E4%B9%A0-%E4%B8%8B/index.html">
<meta property="og:site_name" content="Schwertlilien">
<meta property="og:description" content="期末复习2  各分析考试占比较少。  [TOC] Ch5 相关分析  不考的：  样本复相关系数分布（独立性检验，不考） 典型相关分析所有k步、作用 样本典型相关分析 典型相关变量个数检验 广义相关系数   5.1 复相关系数 5.1.1 总体复相关系数  知道基本定义即可。证明说是很简单，那么有可能考。  变量\(y_1\)与向量\(Y_2\)之间的复相">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-12-18T02:00:49.000Z">
<meta property="article:modified_time" content="2024-12-18T02:01:31.765Z">
<meta property="article:author" content="Schwertlilien">
<meta property="article:tag" content="多元统计分析">
<meta property="article:tag" content="笔记">
<meta name="twitter:card" content="summary"><title>多元统计分析-复习(下) - Schwertlilien - -----personal blog-----</title><link rel="shortcut icon" href="/img/site-icon.png">
<link rel="stylesheet" href="/css/style.css" id="dm-light">


<link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/6.4.2/css/all.min.css">

<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="top-nav" ondblclick="scrollToTop()"><div class="nav-info"><div class="nav-icon"><img id="nav-icon" src="/img/site-icon.png"/></div><div class="nav-title"><a id="nav-title" href="/" title="主页">Schwertlilien</a></div></div><div class="nav-ribbon"><div class="top-menu-expanded"><a class="top-menu-item" href="/archives"><span>归档</span></a><a class="top-menu-item" href="/categories"><span>分类</span></a><a class="top-menu-item" href="/tags"><span>标签</span></a><a class="top-menu-item" href="/about"><span>关于</span></a></div><div class="top-search" onclick="toggleSearchWindow()"><div id="top-search-btn" title="搜索"><i class="icon fa-solid fa-magnifying-glass"></i><span>搜索</span></div></div><div id="top-menu-btn" onclick="openTopMenu()" title="打开菜单"><i class="fa-solid fa-bars fa-lg"></i></div></div></div></header><div id="top-menu-hidden"><div class="menu-hidden-content"><div class="menu-hidden-nav"><a class="menu-hidden-item" href="/archives"><i class="fa-solid fa-box-archive fa-sm"></i><span>归档</span></a><a class="menu-hidden-item" href="/categories"><i class="fa-regular fa-folder-open fa-sm"></i><span>分类</span></a><a class="menu-hidden-item" href="/tags"><i class="fa-solid fa-tags fa-sm"></i><span>标签</span></a><a class="menu-hidden-item" href="/about"><i class="fa-solid fa-paw fa-sm"></i><span>关于</span></a></div></div><div class="menu-hidden-blank" onclick="closeTopMenu()"></div></div>
<div class="blog-info"><div class="blog-pic"><img id="blog-pic" src="/img/site-icon.png"/></div><div class="blog-title"><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i><span>Schwertlilien</span><i class="fa-solid fa-paw fa-2xs fa-rotate-by"></i></div><div class="blog-desc">As a recoder: notes and ideas.</div></div><div class="main"><div class="main-content"><article class="post"><div class="post-title"><h1><i class="fa-solid fa-paw"></i>多元统计分析-复习(下)</h1></div><div class="post-info"><div class="post-info-first-line"><div class="post-date"><i class="icon fa-regular fa-calendar-plus" title="发布日期"></i><time class="publish-time">2024-12-18</time><i class="icon fa-regular fa-calendar-check" title="更新日期"></i><time class="update-time">2024-12-18</time></div>

<div class="post-tags"><i class="icon fa-solid fa-tags" title="标签"></i><a class="post-tag" href="/tags/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/">多元统计分析</a><i class="icon fa-solid fa-tags" title="标签"></i><a class="post-tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a></div></div><div class="post-info-second-line"><div class="post-copyright"><i class="icon fa-brands fa-creative-commons" title="版权声明"></i><span>版权声明: </span><a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh-hans" title="CC BY-NC-ND 4.0">署名-非商业性使用-禁止演绎 4.0</a></div>
<div class="post-word-count"><i class="icon fa-solid fa-pen-to-square"></i><span>全文约5.5K字</span></div><div class="pageview-post"><i class="icon fa-regular fa-eye"></i><span id="busuanzi_container_page_pv">阅读次数: <span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner"></i></span></span></div></div></div><div class="post-content"><h1 id="期末复习2">期末复习2</h1>
<blockquote>
<p>各分析考试占比较少。</p>
</blockquote>
<p>[TOC]</p>
<h2 id="ch5-相关分析">Ch5 相关分析</h2>
<blockquote>
<p>不考的：</p>
<ul>
<li>样本复相关系数分布（独立性检验，不考）</li>
<li>典型相关分析所有k步、作用</li>
<li>样本典型相关分析</li>
<li>典型相关变量个数检验</li>
<li>广义相关系数</li>
</ul>
</blockquote>
<h3 id="复相关系数">5.1 复相关系数</h3>
<h4 id="总体复相关系数">5.1.1 总体复相关系数</h4>
<blockquote>
<p>知道基本定义即可。证明说是很简单，那么有可能考。</p>
</blockquote>
<p>变量<span class="math inline">\(y_1\)</span>与向量<span
class="math inline">\(Y_2\)</span>之间的复相关系数为： <span
class="math display">\[
\rho_{y_1,Y_2} =
\sqrt{\frac{\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}}{\sigma_{11}}}
\]</span> 其中，<span
class="math inline">\(\sigma_{11}=\text{Var}(y_1)\)</span>，<span
class="math inline">\(\Sigma_{22}=\text{Cov}(Y_2)\)</span>，<span
class="math inline">\(\Sigma_{12}=\text{Cov}(y_1,Y_2)\)</span>。</p>
<blockquote>
<p>定义的过程：设随机向量<span class="math inline">\(Y \sim N_p(\mu,
\Sigma)\)</span>，其中<span
class="math inline">\(\Sigma&gt;0\)</span>。</p>
<p>将<span class="math inline">\(Y\)</span>，<span
class="math inline">\(\mu\)</span>和<span
class="math inline">\(\Sigma\)</span>分别剖分为： <span
class="math display">\[
Y = \begin{pmatrix} y_1 \\ Y_2 \end{pmatrix}, \quad \mu =
\begin{pmatrix} \mu_1 \\ \mu_2 \end{pmatrix}, \quad \Sigma =
\begin{pmatrix} \sigma_{11} &amp; \Sigma_{12} \\ \Sigma_{21} &amp;
\Sigma_{22} \end{pmatrix}
\]</span> 其中，<span class="math inline">\(y_1, \mu_1
\in\mathbb{R}^1\)</span>；<span
class="math inline">\(\sigma_{11}&gt;0\)</span>；<span
class="math inline">\(Y_2, \mu_2, \Sigma_{21}=\Sigma_{12}&#39;
\in\mathbb{R}^{p - 1}\)</span>；<span
class="math inline">\(\Sigma_{22}\)</span>是<span
class="math inline">\((p - 1)\)</span>阶正定阵。</p>
<p>考虑<span class="math inline">\(y_1\)</span>与<span
class="math inline">\(a&#39;Y_2\)</span>之间的简单相关系数，其中<span
class="math inline">\(a \in\mathbb{R}^{p - 1}\)</span>， <span
class="math display">\[
\begin{align}
\rho_{y_1,a&#39;Y_2} &amp;=
\frac{\text{Cov}(y_1,a&#39;Y_2)}{\sqrt{\text{Var}(y_1)}\sqrt{\text{Var}(a&#39;Y_2)}}
=
\frac{\text{Cov}(y_1,Y_2)a}{\sqrt{\sigma_{11}}\sqrt{a&#39;\text{Var}(Y_2)a}}\\
&amp;= \frac{\Sigma_{12}a}{\sqrt{\sigma_{11}}\sqrt{a&#39;\Sigma_{22}a}}
\end{align}
\]</span> 则定义<span class="math inline">\(y_1\)</span>与<span
class="math inline">\(Y_2\)</span>的复相关系数为: <span
class="math display">\[
\rho_{y_1,Y_2} = \sup_{a \in R^{p - 1}} \rho_{y_1,a&#39;Y_2} =
\frac{1}{\sqrt{\sigma_{11}}} \sup_{a \in R^{p - 1}}
\frac{\Sigma_{12}a}{\sqrt{a&#39;\Sigma_{22}a}}
\]</span> 由<span
class="math inline">\(\rho_{y_1,Y_2}\)</span>的非负性、Cauchy -
Schwarz不等式知 : <span class="math display">\[
\rho_{y_1,Y_2} = \frac{1}{\sqrt{\sigma_{11}}} \sqrt{\sup_{a \in R^{p -
1}} \frac{(\Sigma_{12}a)^2}{a&#39;\Sigma_{22}a}} =
\sqrt{\frac{\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}}{\sigma_{11}}}
\]</span></p>
</blockquote>
<p><strong>定理 1</strong>: 当<span class="math inline">\(a =
\Sigma_{22}^{-1}\Sigma_{21}\)</span>时，<span
class="math inline">\(y_1-a&#39;Y_2\)</span>的方差取得最小值：<span
class="math inline">\(\sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}=\text{Var}(y_1|Y_2)\)</span>，<span
class="math inline">\(y_1\)</span>与<span
class="math inline">\(a&#39;Y_2+a_0\)</span>最接近，<span
class="math inline">\(a+0=E(y_1)-a&#39;E(Y_2)\)</span>。</p>
<p><span class="math inline">\(y_1\)</span>与<span
class="math inline">\(a&#39;Y_2\)</span>的相关系数最大，为复相关系数<span
class="math inline">\(\rho_{y_1,Y_2}\)</span>，本质上刻画了<span
class="math inline">\(y_1\)</span>和<span
class="math inline">\(Y_2\)</span>的线性相关程度。</p>
<blockquote>
<p><strong>证明</strong>： 对任意<span class="math inline">\(b
\in\mathbb{R}^{p - 1}\)</span>，有 : <span class="math display">\[
\begin{align*} \text{Var}(y_1 - b&#39;Y_2)&amp;=\text{Var}[(y_1 -
a&#39;Y_2)+(a - b)&#39;Y_2]\\ &amp;=\text{Var}(y_1 - a&#39;Y_2)+(a -
b)&#39;\text{Cov}(Y_2)(a - b)\\&amp;+2\text{Cov}[(y_1 - a&#39;Y_2),(a -
b)&#39;Y_2] \end{align*}
\]</span> 由于<span class="math inline">\(a =
\Sigma_{22}^{-1}\Sigma_{21}\)</span>，则有: <span
class="math display">\[
\begin{align*} \text{Cov}[(y_1 -
a&#39;Y_2),Y_2]&amp;=\text{Cov}(y_1,Y_2)-a&#39;\text{Cov}(Y_2,Y_2)\\
&amp;=\Sigma_{12}-a&#39;\Sigma_{22}\\ &amp;=0 \end{align*}
\]</span> 方差关系有： $$ <span class="math display">\[\begin{align*}
Var(y_1 - b&#39;Y_2) &amp;= Var(y_1 - a&#39;Y_2)+(a - b)&#39;Var(Y_2)(a
- b)\\ &amp;= Var(y_1 - a&#39;Y_2)+(a - b)&#39;\Sigma_{22}(a - b)\\
&amp;\geq Var(y_1 - a&#39;Y_2) \\\\

Var(y_1 - a&#39;Y_2) &amp;=
Var(y_1)+Var(a&#39;Y_2)-2Cov(y_1,a&#39;Y_2)\\ &amp;=
\sigma_{11}+\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}-2\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}\\
&amp;= \sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}\\ &amp;=
Var(y_1|Y_2)
\end{align*}\]</span> $$ 由定理1知：<span class="math inline">\(Var(y_1
- a&#39;Y_2)\)</span>达最小意味着<span
class="math inline">\(y_1-\mu_1\)</span>与<span
class="math inline">\(a&#39;Y_2 - a&#39;\mu_2\)</span>最接近，即<span
class="math inline">\(y_1\)</span>与<span class="math inline">\((\mu_1 -
a&#39;\mu_2)+a&#39;Y_2\)</span>最接近。</p>
<p><strong>因此可以用<span class="math inline">\((p -
1)\)</span>个预报因子<span
class="math inline">\(Y_2\)</span>的线性组合来预测单个因变量<span
class="math inline">\(y_1\)</span>，其最优斜率为<span
class="math inline">\(a\)</span>，最优截距为<span
class="math inline">\((\mu_1 - a&#39;\mu_2)\)</span>。</strong></p>
<p>注意到： <span class="math display">\[
\begin{align*} E(y_1|Y_2) &amp;= \mu_1+\Sigma_{12}\Sigma_{22}^{-1}(Y_2 -
\mu_2)\\ &amp;= \mu_1+a&#39;(Y_2 - \mu_2)\\ &amp;= (\mu_1 -
a&#39;\mu_2)+a&#39;Y_2 \end{align*}
\]</span> 条件期望是最优(方差最小)的线性预测。</p>
</blockquote>
<h4 id="样本复相关系数">5.1.2 样本复相关系数</h4>
<blockquote>
<p>在总体复相关系数的基础上，用样本估计替换。</p>
</blockquote>
<p>设总体<span
class="math inline">\(X\stackrel{d}{\sim}N_{p}(\mu,\Sigma)\)</span>，其样本为<span
class="math inline">\(x_1,\cdots,x_n\)</span>。考虑<span
class="math inline">\(X\)</span>的剖分<span
class="math inline">\(X=(x^{(1)},(X^{(2)})&#39;)&#39;\)</span>。</p>
<p>记<span class="math inline">\(\bar{x}\)</span>，<span
class="math inline">\(V\)</span>和<span
class="math inline">\(S\)</span>分别为样本均值、样本离差阵和样本协差阵，并对它们作相应剖分。</p>
<p>则由<span class="math inline">\(x^{(1)}\)</span>与<span
class="math inline">\(X^{(2)}\)</span>的复相关系数: <span
class="math display">\[
\rho_{x^{(1)},X^{(2)}}=\sqrt{\frac{\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}}{\sigma_{11}}}
\]</span> 定义<span class="math inline">\(x^{(1)}\)</span>与<span
class="math inline">\(X^{(2)}\)</span>的样本复相关系数为: <span
class="math display">\[
r_{x^{(1)},X^{(2)}}=\sqrt{\frac{V_{12}V_{22}^{-1}V_{21}}{v_{11}}}
\]</span> 以及<span class="math inline">\(a\)</span>的估计为<span
class="math inline">\(\hat{a}=V_{22}^{-1}V_{21}\)</span>。不难知道，它们分别是复相关系数<span
class="math inline">\(\rho_{x^{(1)},X^{(2)}}\)</span>和方向<span
class="math inline">\(a\)</span>的极大似然估计。</p>
<h3 id="典型相关分析定义">5.2 典型相关分析定义</h3>
<blockquote>
<p>不太确定定义考不考，所以列上了。</p>
</blockquote>
<p>设<span
class="math inline">\(X=(X_1,\dots,X_p)&#39;,Y=(Y_1,\dots,Y_q)&#39;\)</span>分别为p维和q维随机向量：<span
class="math inline">\(\begin{pmatrix}X\\Y\end{pmatrix}\sim
N_{p+q}(\mu,\Sigma)\)</span>，其协方差矩阵为： <span
class="math display">\[
\text{Cov}\begin{pmatrix}X\\Y\end{pmatrix}
=\Sigma=\begin{pmatrix}\Sigma_{11}&amp;\Sigma_{12}\\\Sigma_{21}&amp;\Sigma_{22}\end{pmatrix}
\]</span> 其中：<span class="math inline">\(\Sigma_{11}:p\times
p,\Sigma_{22}:q\times q,\Sigma_{12}=\Sigma_{21}&#39;:p\times
q\)</span>，<span
class="math inline">\(\Sigma_{11},\Sigma_{22}\)</span>正定。</p>
<p>设a和b分别为p维和q维任意非零的常数向量： <span
class="math display">\[
\rho(a&#39;X,b&#39;Y)=\frac{a&#39;\Sigma_{12}b}{\sqrt{(a&#39;\Sigma_{11}a)(b&#39;\Sigma_{22}b)}}
\]</span> <strong>由于相关系数<span
class="math inline">\(\rho(a&#39;X,b&#39;Y)\)</span>不受a和b常数倍的影响，</strong>为简单起见，对<span
class="math inline">\(a&#39;X,b&#39;Y\)</span>进行标准化，令： <span
class="math display">\[
Var(a&#39;X)=a&#39;\Sigma_{11}a=1,\quad
Var(b&#39;Y)=b&#39;\Sigma_{22}b=1
\]</span></p>
<p><strong>(书p485)定理13.1.1</strong>：<span
class="math inline">\(a&#39;X\)</span>和<span
class="math inline">\(b&#39;Y\)</span>的最大相关系数为： <span
class="math display">\[
\max_{a,b}\rho(a&#39;X,b&#39;Y)=\sqrt{\lambda_1}
\]</span> 在标准化的方差约束条件下，最大值在<span
class="math inline">\(a\frac{1}{\sqrt{\lambda_1}\Sigma_{11}^{-1}\Sigma_{12}b},b=\Sigma_{22}^{-1}\beta\)</span>时达到，其中<span
class="math inline">\(\lambda_1,\beta\)</span>分别为矩阵<span
class="math inline">\(D=\Sigma_{22}^{-\frac 1
2}\Sigma_{21}\Sigma_{11}^{-1}\Sigma_{12}\Sigma_{22}^{-\frac 1
2}\)</span>的最大特征值和最大特征值对应的特征向量。</p>
<h2 id="ch6-pca">Ch6 PCA</h2>
<blockquote>
<p><strong>不考的：</strong></p>
<ul>
<li>R-PCA</li>
<li>样本-PCA</li>
<li>PCA-统计推断</li>
<li>PCA-检验问题</li>
</ul>
</blockquote>
<hr />
<blockquote>
<p><strong>基本上考的方式</strong>： PCA=方差最大</p>
<ul>
<li><p>给出计算好的<span
class="math inline">\(\lambda\)</span>，指出第一、第二主成分。</p></li>
<li><p>对应的第一主成分是什么意思？对应的<strong>方差</strong>是多少？把特征根分解写出来。</p></li>
<li><p>顶多考一下基本概念。</p></li>
</ul>
</blockquote>
<p>记<span class="math inline">\(X\)</span>是<span
class="math inline">\(p\)</span>维随机向量(<span
class="math inline">\(p&gt;1,Cov(X)=\Sigma\)</span>)，我们想基于<span
class="math inline">\(X\)</span>，找到变量<span
class="math inline">\(Y=a&#39;X\)</span>(<span
class="math inline">\(a\in \mathbb{R}^p, X\)</span>的线性组合)，令<span
class="math inline">\(Y\)</span>的方差尽可能地大，足以代表<span
class="math inline">\(X\)</span>的散布。</p>
<blockquote>
<p><span class="math inline">\(a\in\mathbb{R}^{m\times
p},X\in\mathbb{R}^{p\times1},Y\in\mathbb{R}^{m\times1}\)</span></p>
</blockquote>
<p>因为<span class="math inline">\(Cov(X)=\Sigma,
Var(a&#39;X)=a&#39;Cov(X)a=a&#39;\Sigma a\)</span>，这表明若不对<span
class="math inline">\(a\)</span>施加约束，则<span
class="math inline">\(a&#39;X\)</span>的最大方差<span
class="math inline">\(\rightarrow \infty\)</span>。</p>
<p>所以对<span class="math inline">\(a\)</span>施加正则化约束：<span
class="math inline">\(a&#39;a=1\)</span>，使得优化问题为： <span
class="math display">\[
\sup_{a&#39;a=1}Var(a&#39;X)=\sup_{a&#39;a=1} a&#39;\Sigma a
\]</span> 令<span class="math inline">\(\Sigma\)</span>的特征根为<span
class="math inline">\(\lambda_{1}\geq\cdots\geq\lambda_{p}\geq0\)</span>，与这些特征根对应的正则正交特征向量为<span
class="math inline">\(\alpha_{1},\cdots,\alpha_{p}\)</span>。 易知:
<span class="math display">\[
\alpha_{1}=\alpha_{1}=(a_{11},\cdots,a_{1p})&#39;\\
V_{ar}(a_{1}&#39;X)=a_{1}&#39;\Sigma a_{1}=\lambda_{1}
\]</span> 则第一主成份：</p>
<ul>
<li>方向：总体协差阵的最大特征根所对应的正则特征向量。</li>
<li>方差：总体协差阵的最大特征根。</li>
</ul>
<h2 id="ch7-因子分析">Ch7 因子分析</h2>
<blockquote>
<p>知道有这种模型，知道概念。</p>
<p>会写其协方差矩阵，</p>
<p>反推说简答的考, 推测考点</p>
<ul>
<li><p>正交因子模型协方差结构检验、写似然比</p></li>
<li><p>斜交旋转（因为简单）</p></li>
<li><p>因子得分（只是反过来当回归估计）</p></li>
</ul>
<p><strong>不考的</strong>：</p>
<ul>
<li>因子载荷矩阵的估计、极大似然估计</li>
<li>极大似然估计的迭代算法</li>
<li>公共因子&gt;2</li>
</ul>
</blockquote>
<h3 id="正交因子模型">7.1 正交因子模型</h3>
<p>令<span class="math inline">\(x\in\mathbb{R}^p\)</span>, <span
class="math inline">\(x=\mu+Af+u\)</span>.</p>
<p><span class="math inline">\(x\)</span>具有因子结构(<span
class="math inline">\(f\)</span>与<span
class="math inline">\(u\)</span>相互独立):</p>
<table>
<colgroup>
<col style="width: 10%" />
<col style="width: 16%" />
<col style="width: 24%" />
<col style="width: 48%" />
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(\mu\)</span></th>
<th><span class="math inline">\(A\)</span></th>
<th><span class="math inline">\(f\)</span></th>
<th><span class="math inline">\(u\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(p\)</span>维常数向量</td>
<td><span class="math inline">\(p\times m\)</span>阶常数矩阵</td>
<td><span class="math inline">\(f\sim N_{m}(0, I_{m}),\ m &lt;
p\)</span></td>
<td><span class="math inline">\(u\sim N_{p}(0, D),\
D=\text{diag}(\sigma_{1}^{2},\cdots,\sigma_{p}^{2})\)</span></td>
</tr>
<tr class="even">
<td></td>
<td>因子载荷矩阵</td>
<td>公共因子</td>
<td>特殊因子</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
\text{Cov}(x)=\Sigma = AA^{\prime}+D
\]</span></p>
<blockquote>
<p>注意：因子载荷矩阵并不唯一，因为对任意<span
class="math inline">\(m\)</span>阶正交矩阵<span
class="math inline">\(T\)</span>，有: <span class="math display">\[
\begin{align}x&amp;=\mu + Af + u\\
&amp;=\mu+(AT)(T^{\prime}f)+u\\
&amp;=\mu+(AT)f^{*}+u\\\\
f^{*}&amp;=T^{\prime}f\sim N_{m}(0, I_{m})\\
\text{Cov}(x)&amp;=AA^{\prime}+D=(AT)(AT)^{\prime}+D
\end{align}
\]</span></p>
</blockquote>
<h3 id="因子载荷矩阵的表示">7.2 因子载荷矩阵的表示</h3>
<blockquote>
<p><strong>Q: 在给定<span class="math inline">\(x\)</span>的相关阵<span
class="math inline">\(R\)</span>和对角阵<span
class="math inline">\(D\)</span>的条件下，如何求解<span
class="math inline">\(A\)</span>？ </strong></p>
</blockquote>
<p>约相关阵：<span class="math inline">\(R^{*}=R -
D=AA^{\prime}\)</span></p>
<p>易知，<span class="math inline">\(R^{*}\)</span>的对角元素为<span
class="math inline">\(h_{i}^{2}\)</span>，<span
class="math inline">\(1\leq i\leq p\)</span>，其它元素与<span
class="math inline">\(R\)</span>一样，且非负定。</p>
<blockquote>
<p><span class="math display">\[
R^*=AA&#39;=\begin{pmatrix}
a_{11}&amp;a_{12}&amp;\cdots&amp;a_{1m}\\
a_{21}&amp;a_{22}&amp;\cdots&amp;a_{2m}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
a_{p1}&amp;a_{p2}&amp;\cdots&amp;a_{pm}\\
\end{pmatrix}\begin{pmatrix}
a_{11}&amp;a_{21}&amp;\cdots&amp;a_{p1}\\
a_{12}&amp;a_{22}&amp;\cdots&amp;a_{p2}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
a_{1m}&amp;a_{2m}&amp;\cdots&amp;a_{pm}\\
\end{pmatrix}\\
R^*_{ii}=A_{i*}·A_{i*}&#39;=\sum^m_{j=1}a_{ij}^2=h_{i}^2\\
R^*_{ij}=A_{i*}·A_{j*}&#39;=\sum^m_{k=1}a_{ik} a_{jk}
\]</span></p>
</blockquote>
<p>记<span class="math inline">\(R^*\)</span>内的元素为<span
class="math inline">\(r^*_{ij}=\sum^m_{k=1}a_{ik} a_{jk},\ 1\le j,k\le
p\)</span>.</p>
<p><strong>目标</strong>：求解<span
class="math inline">\(A\)</span>的各列，使得“贡献”<span
class="math inline">\(g_{1}^{2}\geq\cdots\geq g_{m}^{2}\)</span>.</p>
<p><strong>要求</strong>：使得<span
class="math inline">\(g_{1}^{2}=\sum_{i =
1}^{p}a_{i1}^{2}\)</span>达到最大值的解。</p>
<p><strong>利用特征根和特征向量求解</strong>:</p>
<p>记<span
class="math inline">\(\lambda_{1}\geq\cdots\geq\lambda_{p}\geq0\)</span>为<span
class="math inline">\(R^{*}\)</span>的特征根，其对应的正则正交特征向量分别为<span
class="math inline">\(\alpha_{1},\cdots,\alpha_{p}\)</span>。 则 : <span
class="math display">\[
\begin{align}R^{*}&amp;=U\Lambda U&#39;=U\Lambda^{\frac 1 2}
U&#39;=AA&#39;
\\&amp;=(\alpha_{1},\cdots,\alpha_{p})\text{diag}(\lambda_{1},\cdots,\lambda_{p})(\alpha_{1},\cdots,\alpha_{p})^{\prime}\\
&amp;=(\alpha_{1},\cdots,\alpha_{p})\text{diag}(\sqrt{\lambda_{1}},\cdots,\sqrt{\lambda_{p}})\text{diag}(\sqrt{\lambda_{1}},\cdots,\sqrt{\lambda_{p}})(\alpha_{1},\cdots,\alpha_{p})^{\prime}\\\\
A &amp;=
(\alpha_{1},\cdots,\alpha_{m})\text{diag}(\sqrt{\lambda_{1}},\cdots,\sqrt{\lambda_{m}})
\end{align}
\]</span> 其中<span class="math inline">\(m\)</span>是<span
class="math inline">\(R^{*}\)</span>的秩。</p>
<h3 id="因子旋转-方差最大的正交旋转varimax旋转">7.4
因子旋转-方差最大的正交旋转(Varimax旋转)</h3>
<p>先考虑两个因子的正交旋转，设因子载荷矩阵和正交矩阵为：</p>
<p><span
class="math inline">\(B=AT,T=\begin{pmatrix}\cos(\varphi)&amp;-\sin(\varphi)\\
\sin(\varphi)&amp;cos(\varphi) \end{pmatrix}\)</span>, T是旋转矩阵。</p>
<p>令<span class="math inline">\(A=(a_1,a_2), B=(b_1,b_2)\)</span> <span
class="math display">\[
\begin{cases}
b_1=a_1\cos(\varphi)-a_2\sin(\varphi)\\
b_2=a_1\sin(\varphi)+a_2\cos(\varphi)
\end{cases}
\]</span></p>
<blockquote>
<p><strong>目标：</strong>旋转后，因子的“贡献”越分散越好。</p>
<p><strong>结果：</strong><span
class="math inline">\(x\)</span>可分为两部分，一部分主要与第一因子有关，另一部分主要与第二因子有关。</p>
</blockquote>
<p>定义<span class="math inline">\(b_1\)</span>和<span
class="math inline">\(b_2\)</span>的相对方差： <span
class="math display">\[
V_i(\varphi)=\frac 1
p\sum^p_{j=1}\left(\frac{b_{ji}^2}{h_j^2}\right)-\left(\frac 1
p\sum^p_{j=1}\frac{b_{ji}^2}{h_j^2}\right)^2
\]</span> 其中<span class="math inline">\(h_j\)</span>表示因子对<span
class="math inline">\(x_j\)</span>的影响；要求使得总方差最大，即求：
<span class="math display">\[
\hat\varphi=\arg\max_{\varphi}(V_1(\varphi)+V_2(\varphi))
\]</span> 记：(<span class="math inline">\(1\leq j\leq p\)</span>)</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th><span
class="math inline">\(\mu_{j}=\left(\frac{a_{j1}}{h_{j}}\right)^{2}-\left(\frac{a_{j2}}{h_{j}}\right)^{2}\)</span></th>
<th><span
class="math inline">\(v_{j}=2\left(\frac{a_{j1}}{h_{j}}\right)\left(\frac{a_{j2}}{h_{j}^{2}}\right)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(A=\sum_{j = 1}^{p}\mu_{j}\)</span></td>
<td><span class="math inline">\(B=\sum_{j = 1}^{p}v_{j}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(C=\sum_{j =
1}^{p}(\mu_{j}^{2}-v_{j}^{2})\)</span></td>
<td><span class="math inline">\(D=\sum_{j =
1}^{p}2\mu_{j}v_{j}\)</span></td>
</tr>
</tbody>
</table>
<p>此法具有显式解： <span class="math display">\[
\tan(4\hat\varphi)=\frac{D-2\frac{AB}{p}}{C-\frac{A^2-B^2}{p}}
\]</span> 进而得正交矩阵： <span class="math display">\[
T=\begin{pmatrix}\cos(\hat\varphi)&amp;-\sin(\hat\varphi)\\
\sin(\hat\varphi)&amp;cos(\hat\varphi) \end{pmatrix}
\]</span></p>
<p>取得的方差<span
class="math inline">\(\hat\varphi\)</span>是有界（其成分都是有界的）、故一定会收敛。</p>
<p>在旋转的同时，都会更接近收敛（比原来好），因此到达停止条件的时候，收敛。</p>
<h3 id="正交因子模型极大似然估计">7.5 正交因子模型极大似然估计</h3>
<p>设<span class="math inline">\(x_1,\cdots,x_n\)</span>是来自总体<span
class="math inline">\(N_p(\mu,\Sigma)\)</span>的样本，其中<span
class="math inline">\(n &gt; p\)</span>，<span
class="math inline">\(\Sigma&gt;0\)</span>。</p>
<p>有关正交因子模型<span class="math inline">\((M)\)</span>的检验问题为:
<span class="math display">\[
H_0:\Sigma = AA&#39;+D
\]</span> 其中<span class="math inline">\(A\)</span>是秩为<span
class="math inline">\(m\)</span>的<span class="math inline">\(p\times
m\)</span>矩阵，<span
class="math inline">\(D=\text{diag}(\sigma_1^2,\cdots,\sigma_p^2)&gt;0\)</span>。</p>
<p>记<span class="math inline">\((A,D)\)</span>的极大似然估计为<span
class="math inline">\((\hat{A},\hat{D})\)</span>，则有: <span
class="math display">\[
L(\hat{A},\hat{D})=\vert\hat{A}\hat{A}&#39;+\hat{D}\vert^{-n/2}\exp\left\{-\frac{n}{2}\text{tr}[(\hat{A}\hat{A}&#39;+\hat{D})^{-1}S]\right\}\\
L(\hat A,\hat D)=\vert\hat A\hat A&#39;+\hat D\vert^{-\frac n
2}\exp\{-\frac {np}2\}
\]</span> 正交因子模型检验的似然比<span
class="math inline">\(\lambda\)</span>为： <span class="math display">\[
\begin{align}
\lambda&amp;=\frac{\sup_{\mu,\Sigma =
AA&#39;+D}\vert\Sigma\vert^{-n/2}\exp\left\{-\frac{n}{2}\text{tr}[\Sigma^{-1}(S
+
(\bar{x}-\mu)(\bar{x}-\mu)&#39;)]\right\}}{\sup_{\mu,\Sigma}\vert\Sigma\vert^{-n/2}\exp\left\{-\frac{n}{2}\text{tr}[\Sigma^{-1}(S
+ (\bar{x}-\mu)(\bar{x}-\mu)&#39;)]\right\}}\\
&amp;=\left(\frac{\vert
S\vert}{\vert\hat{A}\hat{A}&#39;+\hat{D}\vert}\right)^{n/2}
\end{align}
\]</span></p>
<h3 id="斜交旋转">7.6斜交旋转</h3>
<p>设<span class="math inline">\(p\)</span>维随机向量<span
class="math inline">\(\mathbf{x}\)</span>可以表示为： <span
class="math display">\[
\mathbf{x}=\mu + A\mathbf{f}+\mathbf{u}
\]</span> 其中，<span class="math inline">\(\mu\)</span>是<span
class="math inline">\(p\)</span>维常数向量，<span
class="math inline">\(A\)</span>是<span class="math inline">\(p\times
m\)</span>阶常数矩阵，<span class="math inline">\(\mathbf{f}\sim
N_{m}(0, R)\)</span>，<span class="math inline">\(m &lt;
p\)</span>，<span class="math inline">\(R &gt; 0\)</span>为相关阵，<span
class="math inline">\(\mathbf{u}\sim N_{p}(0, D)\)</span>，<span
class="math inline">\(D=\text{diag}(\sigma_{1}^{2},\cdots,\sigma_{p}^{2})\)</span>，<span
class="math inline">\(\mathbf{f}\)</span>与<span
class="math inline">\(\mathbf{u}\)</span>相互独立。</p>
<p>称模型<span class="math inline">\(\mathbf{x}=\mu +
A\mathbf{f}+\mathbf{u}\)</span>为斜交因子模型，称<span
class="math inline">\(\mathbf{f}\)</span>为公共因子，<span
class="math inline">\(\mathbf{u}\)</span>为特殊因子，<span
class="math inline">\(A\)</span>为因子载荷矩阵。</p>
<p><strong>Actually，</strong>存在满秩阵<span
class="math inline">\(T\)</span>，使得<span class="math inline">\(R =
TT^{\prime}\)</span>。若令<span class="math inline">\(B =
AT\)</span>，<span
class="math inline">\(g=T^{-1}\mathbf{f}\)</span>，则： <span
class="math display">\[
\begin{align}
{x}&amp;=\mu + \mathbf A{f}+{u}\\
&amp;=\mu+(\mathbf AT)(T^{-1}{f})+{u}\\
&amp;=\mu+\mathbf Bg+u
\end{align}
\]</span> 易知: <span class="math display">\[
$\text{Cov}(\mathbf{g})=T^{-1}\text{Cov}(\mathbf{f})(T^{\prime})^{-1}=T^{-1}R(T^{\prime})^{-1}=I_{m}
\]</span> 则<span class="math inline">\(x=\mu+\mathbf
Bg+u\)</span>是正交因子模型，<span
class="math inline">\({g}\)</span>是公共因子，<span
class="math inline">\(B\)</span>是正交因子载荷矩阵。</p>
<p>由于<span
class="math inline">\(T\)</span>非正交矩阵，我们称公共因子<span
class="math inline">\({f}=T{g}\)</span>为正交公共因子<span
class="math inline">\({g}\)</span>的斜交旋转。</p>
<h3 id="因子得分">7.7 因子得分</h3>
<p>将因子表示成变量的线性组合（反代）</p>
<p><span class="math inline">\(f=Bx\)</span>, 其中<span
class="math inline">\(B=(b_{ij})_{m\times
p},f\in\mathbb{R}^{m}\)</span>是公共因子, <span
class="math inline">\(x\in\mathbb{R}^p\)</span>是变量。</p>
<ul>
<li>因子得分函数：<span class="math inline">\(f=Bx\)</span></li>
<li>因子得分矩阵：<span class="math inline">\(B\)</span></li>
</ul>
<p>由因子得分函数知: <span class="math display">\[
f_j=\sum_{i = 1}^{p}b_{ji}x_i, \quad 1\leq j\leq m
\]</span></p>
<h4 id="因子得分的计算--计算因子得分矩阵b">7.7.1
因子得分的计算--计算因子得分矩阵<span
class="math inline">\(B\)</span></h4>
<p>假定变量<span
class="math inline">\(\mathbf{x}\)</span>已作标准化处理，即<span
class="math inline">\(E(x_i) = 0\)</span>，<span
class="math inline">\(Var(x_i)=1\)</span>，<span
class="math inline">\(1\leq i\leq p\)</span>。 令<span
class="math inline">\(R = Cov(\mathbf{x})\)</span>，<span
class="math inline">\(R\)</span>也是<span
class="math inline">\(\mathbf{x}\)</span>的相关阵。记<span
class="math inline">\(R=(r_{ij})_{p\times p}\)</span>。</p>
<p>假定因子载荷矩阵<span class="math inline">\(A\)</span>和相关阵<span
class="math inline">\(R\)</span>已知。</p>
<p>对任意<span class="math inline">\(1\leq i\leq p\)</span>，<span
class="math inline">\(1\leq j\leq m\)</span>，有： <span
class="math display">\[
\begin{align}
a_{ij}&amp;=E(x_if_j)\\&amp;=\sum_{k =
1}^{p}b_{jk}E(x_ix_k)\\&amp;=\sum_{k = 1}^{p}r_{ik}b_{jk}
\end{align}
\]</span> 因此对<span class="math inline">\(1\leq j\leq m\)</span>，有：
<span class="math display">\[
\begin{pmatrix} r_{11}&amp;r_{12}&amp;\cdots&amp;r_{1p}\\
r_{21}&amp;r_{22}&amp;\cdots&amp;r_{2p}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
r_{p1}&amp;r_{p2}&amp;\cdots&amp;r_{pp} \end{pmatrix} \begin{pmatrix}
b_{j1}\\ b_{j2}\\ \vdots\\ b_{jp} \end{pmatrix} = \begin{pmatrix}
a_{1j}\\ a_{2j}\\ \vdots\\ a_{pj} \end{pmatrix}
\]</span></p>
<h2 id="ch8-判别分析">Ch8 判别分析</h2>
<blockquote>
<p><strong>不考的：</strong></p>
<ul>
<li>贝叶斯估计、容许性</li>
<li>Fisher判别</li>
<li>SVM</li>
</ul>
</blockquote>
<h3 id="马氏距离mahalanobis距离">8.1 马氏距离(Mahalanobis距离)</h3>
<p>假设有两个正态总体<span
class="math inline">\(G_1,G_2\)</span>，分布分别为<span
class="math inline">\(N_m(\mu_1,V),N_m(\mu_2,V)\)</span>.
判断样本y来自哪个总体。</p>
<p>设<span class="math inline">\(x\)</span>和<span
class="math inline">\(y\)</span>是来自于均值为<span
class="math inline">\(\mu\)</span>，协方差阵为<span
class="math inline">\(\Sigma\)</span>的总体<span
class="math inline">\(G\)</span>的两个样本，定义<strong>样本之间的马氏距离</strong>为:
<span class="math display">\[
d^2(x,y)=(x - y)&#39;\Sigma^{-1}(x - y).
\]</span> 定义<strong><span
class="math inline">\(x\)</span>与总体的距离</strong>为<span
class="math inline">\(x\)</span>与均值<span
class="math inline">\(\mu\)</span>的距离，即: <span
class="math display">\[
d^2(x,G)=(x - \mu)&#39;\Sigma^{-1}(x - \mu).
\]</span></p>
<h4 id="总体具有相同协方差--线性">8.1.1 总体具有相同协方差--线性</h4>
<p>假定两个总体<span
class="math inline">\(G_1,G_2\)</span>具有相同的协方差阵<span
class="math inline">\(V\)</span>.</p>
<p>我们先考虑总体<span class="math inline">\(G_1\)</span>和<span
class="math inline">\(G_2\)</span>分别服从正态分布<span
class="math inline">\(N_m(\mu_1, V)\)</span>和<span
class="math inline">\(N_m(\mu_2,
V)\)</span>的距离判别方法，然后给出一般总体的判别方法。</p>
<blockquote>
<p>思路：利用样本到总体的马氏距离进行判断。 <span
class="math display">\[
d^2(y, G_1)=(y - \mu_1)&#39;V^{-1}(y - \mu_1)\\
d^2(y, G_2)=(y - \mu_2)&#39;V^{-1}(y - \mu_2)
\]</span></p>
</blockquote>
<p>样本到总体的距离差为: <span class="math display">\[
d^2(y, G_1)-d^2(y, G_2)=-2\left(y - \frac{\mu_1 +
\mu_2}{2}\right)&#39;V^{-1}(\mu_1 - \mu_2)
\]</span> 记: <span class="math display">\[
\bar{\mu}=\frac{\mu_1 + \mu_2}{2}\\
W(y)=(y - \bar{\mu})&#39;V^{-1}(\mu_1 - \mu_2)
\]</span> 有: <span class="math display">\[
d^2(y, G_1)-d^2(y, G_2)=-2W(y)
\]</span> 判别准则为: <span class="math display">\[
\begin{cases}y \in G_1, &amp; \text{若} W(y) \geq 0; \\ y \in G_2, &amp;
\text{若} W(y) &lt; 0.\end{cases}
\]</span> 若记<span class="math inline">\(\alpha = V^{-1}(\mu_1 -
\mu_2)\)</span>，则<span class="math inline">\(W(y)=\alpha&#39;(y -
\bar{\mu})\)</span>是<span
class="math inline">\(y\)</span>的线性函数。</p>
<p><strong>则称<span
class="math inline">\(W(y)\)</span>是线性判别函数，称<span
class="math inline">\(\alpha\)</span>是判别系数。</strong></p>
<h5 id="总体参数未知">总体参数未知</h5>
<p>当<span class="math inline">\(\mu_1\)</span>，<span
class="math inline">\(\mu_2\)</span>和<span
class="math inline">\(V\)</span>未知时，需要训练样本来估计总体的这些参数。</p>
<p>假设已知有总体<span class="math inline">\(G_1\)</span>的<span
class="math inline">\(n_1\)</span>个样本<span
class="math inline">\(y_1^{(1)}\)</span>，<span
class="math inline">\(\cdots\)</span>，<span
class="math inline">\(y_{n_1}^{(1)}\)</span>，和总体<span
class="math inline">\(G_2\)</span>的<span
class="math inline">\(n_2\)</span>个样本<span
class="math inline">\(y_1^{(2)}\)</span>，<span
class="math inline">\(\cdots\)</span>，<span
class="math inline">\(y_{n_2}^{(2)}\)</span>。 令: <span
class="math display">\[
\bar{y}^{(1)}=\frac{1}{n_1}\sum_{i = 1}^{n_1}y_i^{(1)},\quad
\bar{y}^{(2)}=\frac{1}{n_2}\sum_{i = 1}^{n_2}y_i^{(2)}\\
\begin{align}
\hat{V}&amp;=\frac{1}{n_1 + n_2 - 2}\left[\sum_{i =
1}^{n_1}(y_i^{(1)}-\bar{y}^{(1)})(y_i^{(1)}-\bar{y}^{(1)})&#39;+\sum_{i
=
1}^{n_2}(y_i^{(2)}-\bar{y}^{(2)})(y_i^{(2)}-\bar{y}^{(2)})&#39;\right]\\
&amp;\overset{\Delta}=\frac{1}{n_1 + n_2 - 2}[S_1 + S_2]
\end{align}
\]</span> 需要注意的是<span
class="math inline">\(S\)</span>表示离差阵、而<span
class="math inline">\(V\)</span>表示协方差阵。此时的判别函数为： <span
class="math display">\[
W(y)=\left( y - \frac{\bar{y}^{(1)} + \bar{y}^{(2)}}{2}
\right)&#39;\hat{V}^{-1} (\bar{y}^{(1)} - \bar{y}^{(2)})
\]</span> 判别准则同上： <span class="math display">\[
\begin{cases}
y\in G_1, 若W(y)\ge0\\
y \in G_2,若W(y)&lt; 0
\end{cases}
\]</span></p>
<h4 id="总体协方差不同--二次判别">8.1.2 总体协方差不同--二次判别</h4>
<p>假设有<span class="math inline">\(k\)</span>个总体<span
class="math inline">\(G_1,\cdots,G_k\)</span>，它们的均值和协差阵分别是<span
class="math inline">\((\mu_1,V_1),\cdots,(\mu_k,V_k)\)</span>。</p>
<h5 id="总体参数已知">总体参数已知</h5>
<p>令： <span class="math display">\[
D_i=\left\{y\in R^m:d^2(y,G_i)\leq\min_{1\leq j\leq k,j\neq
i}d^2(y,G_j)\right\},\ 1\leq i\leq k
\]</span> 则判别规则为: <span class="math display">\[
y属于总体G_i\ \text{if}y\in D_i,\ 1\leq i\leq k
\]</span></p>
<h5 id="总体参数未知-1">总体参数未知</h5>
<p><strong>使用样本均值和样本协方差阵来估计样本</strong>，需要注意的是<span
class="math inline">\(S\)</span>表示离差阵、而<span
class="math inline">\(V\)</span>表示协方差阵。记: <span
class="math display">\[
\bar{y}^{(i)}=\frac{1}{n_i}\sum_{j = 1}^{n_i}y_j^{(i)},\ 1\leq i\leq k\\
\hat{V}_i=\frac{S_i}{n_i - 1},\ 1\leq i\leq k
\]</span></p>
<h3 id="误判概率">8.5 误判概率</h3>
<blockquote>
<p><strong>说是比较简单.</strong></p>
<p>两个正态总体：此时，距离判别、贝叶斯判别和Fisher判别等价。</p>
</blockquote>
<p>考虑两个正态总体的情形. <span
class="math inline">\(G_1,G_2\)</span>分别为<span
class="math inline">\(N_m(\mu_1,V)\)</span>和<span
class="math inline">\(N_m(\mu_2,V)\)</span>。判别函数为: <span
class="math display">\[
W(y)=(y - \frac{\mu_1+\mu_2}{2})&#39;V^{-1}(\mu_1 - \mu_2)
\]</span> 记<span class="math inline">\(P(i|j)\)</span>为样本来自<span
class="math inline">\(G_j\)</span>而被误判为<span
class="math inline">\(G_i\)</span>的概率，<span
class="math inline">\(i\neq j\)</span>。则 : <span
class="math display">\[
P(2|1)=P\{W(y)\leq d|G_1\}\\
P(1|2)=P\{W(y)&gt;d|G_2\}
\]</span> 其中<span
class="math inline">\(d\)</span>为某个常数：距离判别，d=0.</p>
<h2 id="ch9-聚类分析">Ch9 聚类分析</h2>
<blockquote>
<p><strong>考点</strong>：</p>
<ul>
<li>K-means（普通/动态的一次迭代）</li>
</ul>
</blockquote>
<h3 id="k-means">9.1 K-means</h3>
<p><strong>由于初始分类数k事先给定,且迭代过程中不断计算类的重心，故称该聚类方法为k均值法(k-means)</strong>：</p>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="header">
<th>---</th>
<th>K-means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. 初始分类</td>
<td>将几个个体初始分成k类,k事先给定.</td>
</tr>
<tr class="even">
<td>2. 修改分类</td>
<td>计算初始k类的重心。然后对每个个体逐一计算它到初始k类的距离(通常用该个体到类的重心的欧氏距离)。若该个体到其原来的类的距离最近,则它保持类不变，否则它移入离其距离最近的类，重新计算由此变动的两个类的重心。</td>
</tr>
<tr class="odd">
<td>3. 重复迭代</td>
<td>在对所有个体都逐一进行验证,是否需要修改分类之后，重复步骤2),直到没有个体需要移动为止,从而得到最终分类.</td>
</tr>
</tbody>
</table>
<h3 id="动态k-means">9.2 动态K-means</h3>
<p>事先给定3个数: 类别数k,阀值 <span
class="math inline">\(c_1\)</span>和 <span
class="math inline">\(c_2\)</span>, <span
class="math inline">\(c_2&gt;c_1&gt; 0\)</span>.</p>
<blockquote>
<p>相较于K-means, 动态K-means在聚类过程中动态地调整聚类中心的数量
K。通常根据数据的分布和内部结构来自动确定合适的 K 值，避免了手动选择 K
值带来的不确定性。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="header">
<th>---</th>
<th>动态K-means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. 选取聚点</td>
<td>取前k个个体作为初始聚点,计算这k个聚点两两之间的距离若最小的距离比<span
class="math inline">\(c_1\)</span>小,则将最小距离的这两个聚点合并在一起,并用它们的重心作为新的聚点，重复上述过程,直到所有的聚点两两之间的距离都不比<span
class="math inline">\(c_1\)</span>小时为止,<strong>因此，此时聚点的个数可能小于k.</strong></td>
</tr>
<tr class="even">
<td>2. 初始分类</td>
<td>对余下的n-k个个体逐一进行计算，对输入的一个个体，分别计算它到所有聚点的距离。若该个体到所有聚点的距离都大于<span
class="math inline">\(c_2\)</span>，则它作为一个新的聚点，这时所有聚点两两之间的距离都不比<span
class="math inline">\(c_1\)</span>小，否则将它归入离它最近的那一类，并重新计算接受该个体的那个类的重心以代替该类原来的聚点。然后重复步骤1)，再次验证所有聚点两两之间的距离是否都不比<span
class="math inline">\(c_1\)</span>小，如果比<span
class="math inline">\(c_1\)</span>小就将其合并，直到所有聚点两两之间的距离都不比<span
class="math inline">\(c_1\)</span>小时止，<strong>该步完成后，聚点的个数可能小于k，也可能大于k</strong>。</td>
</tr>
<tr class="odd">
<td>3. 重复迭代</td>
<td>在对所有个体都逐一进行验证，是否需要修改分类之后，重复步骤2)，直到没有个体需要移动为止，从而得到最终分类。<strong>这时，最终个体的类别数不一定是
k。</strong></td>
</tr>
</tbody>
</table>
</div><div class="post-end"><div class="post-prev"><a href="/2024/12/20/2024-12-20-%E9%9A%8F%E6%83%B3/" title="上一篇文章"><i class="fa-solid fa-chevron-left fa-lg"></i></a></div><div class="post-next"><a href="/2024/12/17/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90-%E5%A4%8D%E4%B9%A0-%E4%B8%8A/" title="下一篇文章"><i class="fa-solid fa-chevron-right fa-lg"></i></a></div></div></article><div class="comment" id="comment"><script src="https://giscus.app/client.js" data-repo="SchwertLin/SwertLin_Blog_Comment" data-repo-id="R_kgDONXjrCQ" data-category="Announcements" data-category-id="DIC_kwDONXjrCc4Cky9X" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="zh-CN" crossorigin="anonymous" async="async"></script></div><div id="post-toc"><aside class="toc-aside"><div class="toc-title"><span><i class="fa-solid fa-paw"></i>目录</span></div><div class="toc-container" id="toc-body"><ol class="toc-content"><li class="toc-content-item toc-content-level-1"><a class="toc-content-link" href="#%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A02"><span class="toc-content-number">1.</span> <span class="toc-content-text">期末复习2</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#ch5-%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90"><span class="toc-content-number">1.1.</span> <span class="toc-content-text">Ch5 相关分析</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%A4%8D%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-content-number">1.1.1.</span> <span class="toc-content-text">5.1 复相关系数</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#%E6%80%BB%E4%BD%93%E5%A4%8D%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-content-number">1.1.1.1.</span> <span class="toc-content-text">5.1.1 总体复相关系数</span></a></li><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#%E6%A0%B7%E6%9C%AC%E5%A4%8D%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-content-number">1.1.1.2.</span> <span class="toc-content-text">5.1.2 样本复相关系数</span></a></li></ol></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%85%B8%E5%9E%8B%E7%9B%B8%E5%85%B3%E5%88%86%E6%9E%90%E5%AE%9A%E4%B9%89"><span class="toc-content-number">1.1.2.</span> <span class="toc-content-text">5.2 典型相关分析定义</span></a></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#ch6-pca"><span class="toc-content-number">1.2.</span> <span class="toc-content-text">Ch6 PCA</span></a></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#ch7-%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90"><span class="toc-content-number">1.3.</span> <span class="toc-content-text">Ch7 因子分析</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E6%AD%A3%E4%BA%A4%E5%9B%A0%E5%AD%90%E6%A8%A1%E5%9E%8B"><span class="toc-content-number">1.3.1.</span> <span class="toc-content-text">7.1 正交因子模型</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%9B%A0%E5%AD%90%E8%BD%BD%E8%8D%B7%E7%9F%A9%E9%98%B5%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="toc-content-number">1.3.2.</span> <span class="toc-content-text">7.2 因子载荷矩阵的表示</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%9B%A0%E5%AD%90%E6%97%8B%E8%BD%AC-%E6%96%B9%E5%B7%AE%E6%9C%80%E5%A4%A7%E7%9A%84%E6%AD%A3%E4%BA%A4%E6%97%8B%E8%BD%ACvarimax%E6%97%8B%E8%BD%AC"><span class="toc-content-number">1.3.3.</span> <span class="toc-content-text">7.4
因子旋转-方差最大的正交旋转(Varimax旋转)</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E6%AD%A3%E4%BA%A4%E5%9B%A0%E5%AD%90%E6%A8%A1%E5%9E%8B%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-content-number">1.3.4.</span> <span class="toc-content-text">7.5 正交因子模型极大似然估计</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E6%96%9C%E4%BA%A4%E6%97%8B%E8%BD%AC"><span class="toc-content-number">1.3.5.</span> <span class="toc-content-text">7.6斜交旋转</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%9B%A0%E5%AD%90%E5%BE%97%E5%88%86"><span class="toc-content-number">1.3.6.</span> <span class="toc-content-text">7.7 因子得分</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#%E5%9B%A0%E5%AD%90%E5%BE%97%E5%88%86%E7%9A%84%E8%AE%A1%E7%AE%97--%E8%AE%A1%E7%AE%97%E5%9B%A0%E5%AD%90%E5%BE%97%E5%88%86%E7%9F%A9%E9%98%B5b"><span class="toc-content-number">1.3.6.1.</span> <span class="toc-content-text">7.7.1
因子得分的计算--计算因子得分矩阵\(B\)</span></a></li></ol></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#ch8-%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90"><span class="toc-content-number">1.4.</span> <span class="toc-content-text">Ch8 判别分析</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E9%A9%AC%E6%B0%8F%E8%B7%9D%E7%A6%BBmahalanobis%E8%B7%9D%E7%A6%BB"><span class="toc-content-number">1.4.1.</span> <span class="toc-content-text">8.1 马氏距离(Mahalanobis距离)</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#%E6%80%BB%E4%BD%93%E5%85%B7%E6%9C%89%E7%9B%B8%E5%90%8C%E5%8D%8F%E6%96%B9%E5%B7%AE--%E7%BA%BF%E6%80%A7"><span class="toc-content-number">1.4.1.1.</span> <span class="toc-content-text">8.1.1 总体具有相同协方差--线性</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-5"><a class="toc-content-link" href="#%E6%80%BB%E4%BD%93%E5%8F%82%E6%95%B0%E6%9C%AA%E7%9F%A5"><span class="toc-content-number">1.4.1.1.1.</span> <span class="toc-content-text">总体参数未知</span></a></li></ol></li><li class="toc-content-item toc-content-level-4"><a class="toc-content-link" href="#%E6%80%BB%E4%BD%93%E5%8D%8F%E6%96%B9%E5%B7%AE%E4%B8%8D%E5%90%8C--%E4%BA%8C%E6%AC%A1%E5%88%A4%E5%88%AB"><span class="toc-content-number">1.4.1.2.</span> <span class="toc-content-text">8.1.2 总体协方差不同--二次判别</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-5"><a class="toc-content-link" href="#%E6%80%BB%E4%BD%93%E5%8F%82%E6%95%B0%E5%B7%B2%E7%9F%A5"><span class="toc-content-number">1.4.1.2.1.</span> <span class="toc-content-text">总体参数已知</span></a></li><li class="toc-content-item toc-content-level-5"><a class="toc-content-link" href="#%E6%80%BB%E4%BD%93%E5%8F%82%E6%95%B0%E6%9C%AA%E7%9F%A5-1"><span class="toc-content-number">1.4.1.2.2.</span> <span class="toc-content-text">总体参数未知</span></a></li></ol></li></ol></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E8%AF%AF%E5%88%A4%E6%A6%82%E7%8E%87"><span class="toc-content-number">1.4.2.</span> <span class="toc-content-text">8.5 误判概率</span></a></li></ol></li><li class="toc-content-item toc-content-level-2"><a class="toc-content-link" href="#ch9-%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90"><span class="toc-content-number">1.5.</span> <span class="toc-content-text">Ch9 聚类分析</span></a><ol class="toc-content-child"><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#k-means"><span class="toc-content-number">1.5.1.</span> <span class="toc-content-text">9.1 K-means</span></a></li><li class="toc-content-item toc-content-level-3"><a class="toc-content-link" href="#%E5%8A%A8%E6%80%81k-means"><span class="toc-content-number">1.5.2.</span> <span class="toc-content-text">9.2 动态K-means</span></a></li></ol></li></ol></li></ol></div></aside><div class="toc-blank" onclick="tocToggle()"></div></div><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for(i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async="async"></script></div></div><div id="tool-bar"><div id="tool-bar-main"><div id="tool-toggle" onclick="toolToggle()" title="设置"><i class="fa-solid fa-gear"></i></div><div id="toc-toggle" onclick="tocToggle()" title="目录"><i class="fa-solid fa-list-ul"></i></div><div id="go-to-comment" onclick="gotoComment()" title="评论"><i class="fa-regular fa-message fa-flip-horizontal"></i></div><div id="back-to-top" onclick="scrollToTop()" title="返回顶部"><i class="fa-solid fa-chevron-up"></i></div></div><div id="tool-bar-more" style="display: none;"><div id="darkmode-switch" onclick="darkmodeSwitch()" title="深色模式"><i class="fa-solid fa-circle-half-stroke"></i></div><div id="font-size-increase" onclick="fontSizeIncrease()" title="放大字体"><i class="fa-solid fa-plus"></i></div><div id="font-size-decrease" onclick="fontSizeDecrease()" title="缩小字体"><i class="fa-solid fa-minus"></i></div></div></div><div id="search-panel"><div class="search-container"><div class="search-head"><div class="search-title"><span><i class="fa-solid fa-paw"></i>搜索</span></div><div class="search-close-btn" onclick="toggleSearchWindow()"><i class="fa-regular fa-circle-xmark"></i></div></div><div class="search-box"><i class="fa-solid fa-magnifying-glass"></i><input id="search-input" type="text" placeholder="请输入需要搜索的内容……" value=""/></div><div class="search-body"><div id="search-count">匹配结果数: </div><div id="search-result"></div><div id="search-result-empty">未搜索到匹配的文章。</div></div></div></div><footer><div class="footer-content"><div class="copyright-info"><i class="fa-regular fa-copyright fa-xs"></i><span>2022 - 2024 </span><a href="/about">Schwertlilien</a><i class="fa-solid fa-cat fa-sm"></i><span>Powered by </span><a href="https://hexo.io/" target="_blank">Hexo</a><span> &amp; </span><a href="https://github.com/chanwj/hexo-theme-meow" target="_blank" title="v2.1.0">Theme Meow</a></div><div class="pageview-site"><span id="busuanzi_container_site_pv">总访问量 : <span id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner"></i></span></span><span id="busuanzi_container_site_uv">总访客数 : <span id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner"></i></span></span></div></div></footer>
<script>const GLOBAL_CONFIG = {
  comment: { theme: 'preferred_color_scheme'}
}
</script>
<script src="/js/third-party/darkmode.js"></script>
<script>var options = {
  dark: '/css/darkmode.css',
  startAt: '24:00',
  endAt: '06:00',
  checkSystemScheme: 'false',
  saveOnToggle: 'true'
};
var darkMode = new DarkMode(options);
// change comment theme synchronously 同步修改评论区主题
if (darkMode.getMode() == "dark" && (true || true)) {
  if (document.getElementById('comment')) {
    document.getElementById('comment').getElementsByTagName('script')[0].setAttribute('data-theme', 'noborder_dark');
  }
}
</script><script>if (localStorage.getItem('font-size')) {
  document.querySelector('.post-content').style.fontSize = localStorage.getItem('font-size') + 'px';
}
</script>
<script src="/js/theme/tool-bar.js"></script>


<script src="/js/theme/menu.js"></script>


<script src="/js/third-party/clipboard.min.js"></script>


<script src="/js/theme/copy.js"></script>
<script>copyCode();
</script>
<script src="/js/jquery-3.7.1.min.js"></script>


<script src="/js/theme/search.js"></script>
<script>searchFunc('/search.xml', 'search-input', 'search-result');
</script></body></html>